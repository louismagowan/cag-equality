{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e3cd615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "## Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "## SVR\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "## Neural networks\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "## LGBM\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4be8e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of annoying LGBM messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"categorical_column in param dict is overridden.\")\n",
    "warnings.filterwarnings(\"ignore\", message='Overriding the parameters from Reference Dataset.')\n",
    "warnings.filterwarnings(\"ignore\", message='The reported value is ignored because this*')\n",
    "warnings.filterwarnings(\"ignore\", message='Found `n_estimators` in params. Will use it*')\n",
    "warnings.filterwarnings(\"ignore\", message='The distribution is specified by*')\n",
    "\n",
    "# Hide optuna logging too\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68780a",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a620a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files to read in\n",
    "gcse_files = glob.glob(\"../fake_data/synthetic_*_gcse_20[1-2][0, 8-9].csv\")\n",
    "npd_files = glob.glob(\"../fake_data/synthetic_npd_ks4_student_20[1-2][0, 8-9].csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908933d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7cb15ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_grades(data = pd.DataFrame, grade_col = str):\n",
    "    \n",
    "    # Drop rows with missing grades\n",
    "    data = data.dropna(subset = grade_col)\n",
    "    # Convert U grade to 0\n",
    "    data.loc[data[grade_col] == \"U\", grade_col] = \"0\"\n",
    "    # Convert grades to numeric from string format\n",
    "    data = data[data[grade_col].isin([str(x) for x in (range(0, 10))])]\n",
    "    data[grade_col] = data[grade_col].astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da99e4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_gcse_data(df = pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes raw GCSE exam data (2017-2020 files), filters it\n",
    "    appropriately and processes it. \n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of raw GCSE data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy to prevent in-place changes\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Make cols lowercase\n",
    "    data.columns = [x.lower() for x in data.columns]\n",
    "    \n",
    "    # Reformat examseries to year col\n",
    "    data[\"year\"] = data.examseries.apply(lambda x: x.split()[1])\n",
    "    \n",
    "    # Remove candidates who were not 16 on 31st August\n",
    "    data = data.query(\"yearendage == 16\")\n",
    "    # Remove private candidates\n",
    "    data = data.query(\"privatecandidate == False\")\n",
    "    # Commented out below since all True in synthetic data\n",
    "    # Remove partial absentees\n",
    "#     data = data.query(\"partialabsence == False\")\n",
    "    # Remove candidates without prior attainment or that weren't matched in NPD\n",
    "    data = data.dropna(subset = [\"normalisedks2score\", \"npdmatchround\"])\n",
    "    \n",
    "    # Remove candidates with 0 prior attainment (errors in data)\n",
    "    data = data[data.normalisedks2score > 0]\n",
    "    \n",
    "    # Remove non-reformed GCSEs\n",
    "    data = data[data.reformphase.isin(['Ofqual-regulated Phase 1 reformed GCSE FC',\n",
    "                                       'Ofqual-regulated Phase 2 reformed GCSE FC'])]\n",
    "    # Recode tier into foundation or not foundation\n",
    "    data.loc[data.tier != \"F\", \"tier\"] = \"Not F\"\n",
    "    \n",
    "    # Process grade column inplace\n",
    "    data = process_grades(data, grade_col = \"grade\")\n",
    "    \n",
    "    # Standardise the KS2 prior attainment to between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    data.normalisedks2score = scaler.fit_transform(data[['normalisedks2score']])\n",
    "    \n",
    "    # Get candidates who took at least 8 GCSEs\n",
    "    grouped = data.groupby(\"uidp\").count()\n",
    "    at_least_8 = set(grouped[grouped.examseries >= 8].index.to_list())\n",
    "    # Get candidates who took English and Maths\n",
    "    eng_math = set(data[data.jcqtitle.isin([\"Mathematics\", \"English language\"])].uidp)\n",
    "    # Get candidates who took English and Maths and >= 8 GCSEs\n",
    "    filtered_ids = at_least_8 & eng_math\n",
    "    # Beware that since this is simulated data, it's wrong\n",
    "    filtered = data[data.uidp.isin(filtered_ids)]\n",
    "    \n",
    "    # Select cols needed for modelling and dropnas\n",
    "    gcse_cols = [\"uidp\", \"year\", \"jcqtitle\", \"tier\", \"centretypedesc\",\n",
    "                 \"normalisedks2score\", \"grade\", \"centreassessmentgrade\"]\n",
    "    filtered = filtered[gcse_cols]\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27b0592",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load and process all the GCSE exam data\n",
    "gcse_data = pd.DataFrame()\n",
    "# Iterate through files\n",
    "for file in gcse_files:\n",
    "    # Perform filtering/pre-processing\n",
    "    year_df = process_gcse_data(pd.read_csv(file))\n",
    "    # Process the CAG column too\n",
    "    if \"2020\" in file:\n",
    "        year_df = process_grades(year_df, \"centreassessmentgrade\")\n",
    "    # Create dummy value for other years\n",
    "    else:\n",
    "        year_df.centreassessmentgrade = np.NaN\n",
    "        \n",
    "    # Merge with other years\n",
    "    gcse_data = pd.concat([gcse_data, year_df])\n",
    "    # Delete var to save memory\n",
    "    del year_df\n",
    "# Reset index\n",
    "gcse_data = gcse_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fc33e6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NPD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096a737e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_npd(data = pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes raw NPD data (2017-2020 files), filters it\n",
    "    appropriately and processes it. \n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of raw NPD data\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Copy to prevent inplace changes\n",
    "    df = data.copy()\n",
    "    # Make cols lowercase\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    # Select the columns that are common across files\n",
    "    npd_cols = [\"uidp\", \"ks4_ealgrp_ptq_ee\", \"ks4_gender\"]\n",
    "    # Get the bases for the columns that change in suffix in each file\n",
    "    col_bases = [\"ethnicgroupmajor\", \"fsmeligible\", \"senprovisionmajor\"]\n",
    "    # Get the suffix part that changes\n",
    "    year_ending = int(file[-6:-4])\n",
    "    # Dynamically select those cols with changing suffixes\n",
    "    npd_cols.extend([col_base + f\"_spr{year_ending}\" for col_base in col_bases])\n",
    "    # Also add in most recent IDACI score\n",
    "    npd_cols.append(sorted([x for x in df.columns if \"idaciscore\" in x])[-1])\n",
    "    \n",
    "    # Select the needed columns\n",
    "    df = df[npd_cols]\n",
    "    # Add in year col\n",
    "    df[\"year\"] = f\"20{year_ending}\"\n",
    "    # Rename columns\n",
    "    clean_cols = [\"uidp\", \"eal\", \"gender\", \"ethnicity\",\n",
    "              \"fsm\", \"sen\", \"idaci\", \"year\"]\n",
    "    df.columns = clean_cols\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8eb496f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_dict = dict()\n",
    "for file in npd_files:\n",
    "    col_dict[file[-8:-4]] = pd.read_csv(file).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5643598",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set(col_dict[\"2020\"]) & set(col_dict[\"2019\"]) & set(col_dict[\"2018\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5581cdf",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set(col_dict[\"2020\"]) - set(col_dict[\"2019\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6737ff1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create df to store each year's data in\n",
    "npd_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through files\n",
    "for file in npd_files:\n",
    "    # Load data\n",
    "    df = pd.read_csv(file)\n",
    "    # Process the NPD data\n",
    "    df = process_npd(df)\n",
    "    # Combine into dataframe\n",
    "    npd_data = pd.concat([npd_data, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2f7cc",
   "metadata": {},
   "source": [
    "# Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae4b2203",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def recode_cols(data = pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Takes processed merged GCSE exam and NPD data (2017-2020 files),\n",
    "    filters it appropriately and processes it. \n",
    "    It recodes several columns into fewer numbers of categories\n",
    "    to make modelling easier.\n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of merged NPD/GCSE data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy to prevent inplace changes\n",
    "    df = data.copy()\n",
    "    # Filter EAL to remove NAs or unclassifieds\n",
    "    df = df[df.eal.isin([1,2])]\n",
    "    # Filter ethnicity to remove unclassifieds/NaNs\n",
    "    df = df[df.ethnicity.isin([\"AOEG\", \"ASIA\", \"BLAC\", \"CHIN\",\n",
    "                          \"MIXD\", \"WHIT\"])]\n",
    "    # Filter and recode SEN to remove unclassifieds and make SEN/not SEN\n",
    "    df = df[df.sen.isin([\"1_NON\", \"2_SNS\", \"3_SS\"])]\n",
    "    df.loc[df.sen != \"1_NON\", \"sen\"] = \"SEN\"\n",
    "    df.loc[df.sen == \"1_NON\", \"sen\"] = \"No SEN\"\n",
    "    \n",
    "    # Drop remaining NaNs from FSM and IDACI cols\n",
    "    df = df.dropna(subset = [\"fsm\", \"idaci\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa27f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join exam data with NPD data\n",
    "merged = npd_data.merge(gcse_data, on = [\"uidp\", \"year\"],\n",
    "                       how = \"inner\")\n",
    "\n",
    "# Recode columns and filter further\n",
    "df = recode_cols(merged)\n",
    "\n",
    "# Drop now unnecesary UIDP and year cols\n",
    "df = df.drop(columns = [\"year\", \"uidp\"])\n",
    "\n",
    "# Convert categorical cols to numerics\n",
    "categorical_cols = [\"eal\", \"gender\", \"ethnicity\", \"fsm\",\n",
    "               \"sen\", \"jcqtitle\", \"tier\", \"centretypedesc\"]\n",
    "# Fit encoder on categorical cols\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(df[categorical_cols])\n",
    "\n",
    "# Create a mapping for reference later\n",
    "mapping = {k:v for k, v in zip(categorical_cols, encoder.categories_)}\n",
    "\n",
    "# Convert categoricals to numerics\n",
    "df[categorical_cols] = encoder.transform(df[categorical_cols])\n",
    "\n",
    "# Split into treatment and control\n",
    "treatment = df[~df.centreassessmentgrade.isna()]\n",
    "control = df[df.centreassessmentgrade.isna()]\n",
    "# Old code, maybe useful for LGBM\n",
    "# df[categorical_cols] = df[categorical_cols].apply(pd.Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ae1b7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into labels and features\n",
    "X = np.array(control.iloc[:, :10], dtype = \"float32\")\n",
    "y = np.array(control.grade, dtype = \"float32\")\n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                   shuffle = True,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b9eb7c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Quick EDA / Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "408ac601",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37c5328b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a62c65cd24427b8fd6d11ede4f7ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a45510b019455eaaa31ec701c84690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4b8bcaab5e4419a3a0b7079ecd535f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ff58b566c743ab974d1443f2a193c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = ProfileReport(df, title = \"eda_check\")\n",
    "report.to_file(\"eda_check.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc97f8",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a94e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to store model results in\n",
    "all_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed23bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, X_test,\n",
    "                  y_train, y_test,\n",
    "                  model, model_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to evaluate a model in terms of\n",
    "    train and test RMSE.\n",
    "    Returns a dataframe of model name and RMSEs.\n",
    "    --------------------------------------------------\n",
    "    X_train = np.array of X data, used to generate train RMSE\n",
    "    X_test = np.array of X data, used to generate test RMSE\n",
    "    y_train = np.array of y data, used to generate train RMSE\n",
    "    y_test = np.array of y data, used to generate test RMSE\n",
    "    model = fitted model instance to use with model.predict\n",
    "    model_name = str, name to save the model under\n",
    "    \"\"\"\n",
    "    # Generate predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    # Evaluate model\n",
    "    train_rmse = mean_squared_error(y_train, train_preds, squared = False)\n",
    "    test_rmse = mean_squared_error(y_test, test_preds, squared = False)\n",
    "\n",
    "    # Store results\n",
    "    results = pd.DataFrame({\"model\": model_name,\n",
    "                            \"train_rmse\": train_rmse,\n",
    "                            \"test_rmse\": test_rmse,\n",
    "                 }, index = [0])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe21bd4",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c618d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"linear\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab6bc63",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bac7ce30",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(X_data,\n",
    "              layer_1_units = 64,\n",
    "              layer_2_units = 64,\n",
    "              batch_normalization = False,\n",
    "              loss = \"mse\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"mse\"]):\n",
    "    \"\"\"\n",
    "    Function to create artificial neural network. Dense layer\n",
    "    units can be specified, as can the use of batch normalization\n",
    "    in between the dense layers (this provides mild regularisation)\n",
    "    and may speed up training.\n",
    "    Returns a compiled Keras model.\n",
    "    --------------------------------------------------\n",
    "    X_data = np.array of X data, used to give input shape to model\n",
    "    layer_1_units = int, number of neurons in 1st hidden layer\n",
    "    layer_2_units = int, number of neurons in 2nd hidden layer\n",
    "    batch_normalization = bool, batch normalize between hidden layers \n",
    "    if true\n",
    "    loss = str, name of loss function to use\n",
    "    optimizer = str or keras.Optimzer object, optimizer to use\n",
    "    metrics = list of strings, evaluation metrics to use\n",
    "    \"\"\"\n",
    "    # Build model\n",
    "    model = Sequential(name = \"MLP\")\n",
    "    # 1st Dense layer\n",
    "    model.add(Dense(units = layer_1_units, activation = \"relu\", input_shape = (X_data.shape[1], ),\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    \n",
    "    # Add batch normalization if desired\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    # 2nd Dense layer\n",
    "    model.add(Dense(units = layer_2_units, activation = \"relu\",\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    # Output layer\n",
    "    model.add(Dense(units = 1, activation = \"linear\",\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    # Compile model\n",
    "    model.compile(**compile_hp)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7362707",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hyperparams used during modelling\n",
    "# Compilation hyperparams\n",
    "compile_hp = dict()\n",
    "compile_hp[\"loss\"] = \"mse\"\n",
    "compile_hp[\"optimizer\"] = optimizers.Adam(learning_rate = 0.001)\n",
    "compile_hp[\"metrics\"] = [\"mse\"]\n",
    "\n",
    "# Fitting hyperparams\n",
    "fit_hp = dict()\n",
    "fit_hp[\"batch_size\"] = 32\n",
    "fit_hp[\"epochs\"] = 200\n",
    "fit_hp[\"validation_split\"] = 0.2\n",
    "# Create callback to select the best model\n",
    "fit_hp[\"callbacks\"] = EarlyStopping(monitor = \"val_loss\",\n",
    "                                         mode = \"min\",\n",
    "                                         restore_best_weights = True,\n",
    "                                         patience = 25)\n",
    "\n",
    "# Eliminate verbose to have a neater notebook \n",
    "fit_hp[\"verbose\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceb267",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c18618f",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:27:19.023567: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 1s - loss: 20.0784 - mse: 20.0784 - val_loss: 16.9620 - val_mse: 16.9620 - 1s/epoch - 353ms/step\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 13.0802 - mse: 13.0802 - val_loss: 22.1561 - val_mse: 22.1561 - 32ms/epoch - 11ms/step\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 6.9596 - mse: 6.9596 - val_loss: 49.4990 - val_mse: 49.4990 - 34ms/epoch - 11ms/step\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 5.0195 - mse: 5.0195 - val_loss: 77.0165 - val_mse: 77.0165 - 33ms/epoch - 11ms/step\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 5.5998 - mse: 5.5998 - val_loss: 64.2733 - val_mse: 64.2733 - 32ms/epoch - 11ms/step\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:27:19.559862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 5.4465 - mse: 5.4465 - val_loss: 43.6236 - val_mse: 43.6236 - 31ms/epoch - 10ms/step\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 5.6512 - mse: 5.6512 - val_loss: 24.6170 - val_mse: 24.6170 - 31ms/epoch - 10ms/step\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 4.1342 - mse: 4.1342 - val_loss: 14.7795 - val_mse: 14.7795 - 37ms/epoch - 12ms/step\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 4.3402 - mse: 4.3402 - val_loss: 11.8381 - val_mse: 11.8381 - 33ms/epoch - 11ms/step\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 4.0281 - mse: 4.0281 - val_loss: 10.5440 - val_mse: 10.5440 - 32ms/epoch - 11ms/step\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 3.8218 - mse: 3.8218 - val_loss: 10.0687 - val_mse: 10.0687 - 34ms/epoch - 11ms/step\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 3.6803 - mse: 3.6803 - val_loss: 9.5612 - val_mse: 9.5612 - 35ms/epoch - 12ms/step\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 3.4486 - mse: 3.4486 - val_loss: 9.4825 - val_mse: 9.4825 - 35ms/epoch - 12ms/step\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 3.1396 - mse: 3.1396 - val_loss: 9.3816 - val_mse: 9.3816 - 34ms/epoch - 11ms/step\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 3.0409 - mse: 3.0409 - val_loss: 9.2092 - val_mse: 9.2092 - 36ms/epoch - 12ms/step\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 2.9286 - mse: 2.9286 - val_loss: 8.7359 - val_mse: 8.7359 - 35ms/epoch - 12ms/step\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 2.9348 - mse: 2.9348 - val_loss: 8.5610 - val_mse: 8.5610 - 43ms/epoch - 14ms/step\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 2.9278 - mse: 2.9278 - val_loss: 8.5244 - val_mse: 8.5244 - 45ms/epoch - 15ms/step\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 2.7847 - mse: 2.7847 - val_loss: 8.5311 - val_mse: 8.5311 - 33ms/epoch - 11ms/step\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 2.9438 - mse: 2.9438 - val_loss: 8.4290 - val_mse: 8.4290 - 33ms/epoch - 11ms/step\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 2.7139 - mse: 2.7139 - val_loss: 8.2741 - val_mse: 8.2741 - 33ms/epoch - 11ms/step\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 2.5021 - mse: 2.5021 - val_loss: 8.2377 - val_mse: 8.2377 - 37ms/epoch - 12ms/step\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 2.7987 - mse: 2.7987 - val_loss: 8.2147 - val_mse: 8.2147 - 34ms/epoch - 11ms/step\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 2.5319 - mse: 2.5319 - val_loss: 8.1823 - val_mse: 8.1823 - 36ms/epoch - 12ms/step\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 2.5111 - mse: 2.5111 - val_loss: 8.1275 - val_mse: 8.1275 - 35ms/epoch - 12ms/step\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 2.3228 - mse: 2.3228 - val_loss: 8.1433 - val_mse: 8.1433 - 32ms/epoch - 11ms/step\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 2.4553 - mse: 2.4553 - val_loss: 8.1018 - val_mse: 8.1018 - 34ms/epoch - 11ms/step\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 2.7514 - mse: 2.7514 - val_loss: 8.0564 - val_mse: 8.0564 - 32ms/epoch - 11ms/step\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 2.4549 - mse: 2.4549 - val_loss: 8.0035 - val_mse: 8.0035 - 153ms/epoch - 51ms/step\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 2.4272 - mse: 2.4272 - val_loss: 8.0049 - val_mse: 8.0049 - 87ms/epoch - 29ms/step\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 2.3500 - mse: 2.3500 - val_loss: 8.0836 - val_mse: 8.0836 - 29ms/epoch - 10ms/step\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 2.3289 - mse: 2.3289 - val_loss: 8.0043 - val_mse: 8.0043 - 33ms/epoch - 11ms/step\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 2.4170 - mse: 2.4170 - val_loss: 8.0271 - val_mse: 8.0271 - 29ms/epoch - 10ms/step\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 2.2666 - mse: 2.2666 - val_loss: 8.0959 - val_mse: 8.0959 - 30ms/epoch - 10ms/step\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 2.2353 - mse: 2.2353 - val_loss: 8.0506 - val_mse: 8.0506 - 29ms/epoch - 10ms/step\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 2.3544 - mse: 2.3544 - val_loss: 8.0500 - val_mse: 8.0500 - 29ms/epoch - 10ms/step\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 2.3715 - mse: 2.3715 - val_loss: 7.9066 - val_mse: 7.9066 - 33ms/epoch - 11ms/step\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 2.3046 - mse: 2.3046 - val_loss: 7.7238 - val_mse: 7.7238 - 33ms/epoch - 11ms/step\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 2.4843 - mse: 2.4843 - val_loss: 7.5860 - val_mse: 7.5860 - 35ms/epoch - 12ms/step\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 2.2860 - mse: 2.2860 - val_loss: 7.5047 - val_mse: 7.5047 - 37ms/epoch - 12ms/step\n",
      "Epoch 41/200\n",
      "3/3 - 0s - loss: 2.5166 - mse: 2.5166 - val_loss: 7.3632 - val_mse: 7.3632 - 35ms/epoch - 12ms/step\n",
      "Epoch 42/200\n",
      "3/3 - 0s - loss: 2.2842 - mse: 2.2842 - val_loss: 7.4629 - val_mse: 7.4629 - 30ms/epoch - 10ms/step\n",
      "Epoch 43/200\n",
      "3/3 - 0s - loss: 2.1877 - mse: 2.1877 - val_loss: 7.4757 - val_mse: 7.4757 - 29ms/epoch - 10ms/step\n",
      "Epoch 44/200\n",
      "3/3 - 0s - loss: 2.2156 - mse: 2.2156 - val_loss: 7.5693 - val_mse: 7.5693 - 30ms/epoch - 10ms/step\n",
      "Epoch 45/200\n",
      "3/3 - 0s - loss: 2.4499 - mse: 2.4499 - val_loss: 7.5437 - val_mse: 7.5437 - 32ms/epoch - 11ms/step\n",
      "Epoch 46/200\n",
      "3/3 - 0s - loss: 2.2433 - mse: 2.2433 - val_loss: 7.3476 - val_mse: 7.3476 - 33ms/epoch - 11ms/step\n",
      "Epoch 47/200\n",
      "3/3 - 0s - loss: 2.4025 - mse: 2.4025 - val_loss: 7.2098 - val_mse: 7.2098 - 33ms/epoch - 11ms/step\n",
      "Epoch 48/200\n",
      "3/3 - 0s - loss: 2.2997 - mse: 2.2997 - val_loss: 7.0942 - val_mse: 7.0942 - 33ms/epoch - 11ms/step\n",
      "Epoch 49/200\n",
      "3/3 - 0s - loss: 2.0520 - mse: 2.0520 - val_loss: 7.0539 - val_mse: 7.0539 - 33ms/epoch - 11ms/step\n",
      "Epoch 50/200\n",
      "3/3 - 0s - loss: 2.3487 - mse: 2.3487 - val_loss: 7.0364 - val_mse: 7.0364 - 33ms/epoch - 11ms/step\n",
      "Epoch 51/200\n",
      "3/3 - 0s - loss: 2.3788 - mse: 2.3788 - val_loss: 7.0280 - val_mse: 7.0280 - 32ms/epoch - 11ms/step\n",
      "Epoch 52/200\n",
      "3/3 - 0s - loss: 2.1013 - mse: 2.1013 - val_loss: 7.0410 - val_mse: 7.0410 - 32ms/epoch - 11ms/step\n",
      "Epoch 53/200\n",
      "3/3 - 0s - loss: 2.5405 - mse: 2.5405 - val_loss: 7.1639 - val_mse: 7.1639 - 30ms/epoch - 10ms/step\n",
      "Epoch 54/200\n",
      "3/3 - 0s - loss: 2.2132 - mse: 2.2132 - val_loss: 7.1038 - val_mse: 7.1038 - 29ms/epoch - 10ms/step\n",
      "Epoch 55/200\n",
      "3/3 - 0s - loss: 2.0008 - mse: 2.0008 - val_loss: 7.0004 - val_mse: 7.0004 - 33ms/epoch - 11ms/step\n",
      "Epoch 56/200\n",
      "3/3 - 0s - loss: 2.1682 - mse: 2.1682 - val_loss: 6.9821 - val_mse: 6.9821 - 34ms/epoch - 11ms/step\n",
      "Epoch 57/200\n",
      "3/3 - 0s - loss: 2.1405 - mse: 2.1405 - val_loss: 6.9884 - val_mse: 6.9884 - 30ms/epoch - 10ms/step\n",
      "Epoch 58/200\n",
      "3/3 - 0s - loss: 1.9539 - mse: 1.9539 - val_loss: 6.9340 - val_mse: 6.9340 - 34ms/epoch - 11ms/step\n",
      "Epoch 59/200\n",
      "3/3 - 0s - loss: 2.1121 - mse: 2.1121 - val_loss: 6.9685 - val_mse: 6.9685 - 31ms/epoch - 10ms/step\n",
      "Epoch 60/200\n",
      "3/3 - 0s - loss: 2.1016 - mse: 2.1016 - val_loss: 6.8998 - val_mse: 6.8998 - 33ms/epoch - 11ms/step\n",
      "Epoch 61/200\n",
      "3/3 - 0s - loss: 1.9005 - mse: 1.9005 - val_loss: 6.6704 - val_mse: 6.6704 - 33ms/epoch - 11ms/step\n",
      "Epoch 62/200\n",
      "3/3 - 0s - loss: 1.9806 - mse: 1.9806 - val_loss: 6.5173 - val_mse: 6.5173 - 33ms/epoch - 11ms/step\n",
      "Epoch 63/200\n",
      "3/3 - 0s - loss: 1.9922 - mse: 1.9922 - val_loss: 6.4161 - val_mse: 6.4161 - 32ms/epoch - 11ms/step\n",
      "Epoch 64/200\n",
      "3/3 - 0s - loss: 2.1563 - mse: 2.1563 - val_loss: 6.4358 - val_mse: 6.4358 - 32ms/epoch - 11ms/step\n",
      "Epoch 65/200\n",
      "3/3 - 0s - loss: 1.8808 - mse: 1.8808 - val_loss: 6.6264 - val_mse: 6.6264 - 29ms/epoch - 10ms/step\n",
      "Epoch 66/200\n",
      "3/3 - 0s - loss: 1.9433 - mse: 1.9433 - val_loss: 6.8485 - val_mse: 6.8485 - 31ms/epoch - 10ms/step\n",
      "Epoch 67/200\n",
      "3/3 - 0s - loss: 1.7811 - mse: 1.7811 - val_loss: 6.9689 - val_mse: 6.9689 - 32ms/epoch - 11ms/step\n",
      "Epoch 68/200\n",
      "3/3 - 0s - loss: 1.7954 - mse: 1.7954 - val_loss: 6.9842 - val_mse: 6.9842 - 29ms/epoch - 10ms/step\n",
      "Epoch 69/200\n",
      "3/3 - 0s - loss: 1.8313 - mse: 1.8313 - val_loss: 6.8746 - val_mse: 6.8746 - 29ms/epoch - 10ms/step\n",
      "Epoch 70/200\n",
      "3/3 - 0s - loss: 1.7843 - mse: 1.7843 - val_loss: 6.7971 - val_mse: 6.7971 - 29ms/epoch - 10ms/step\n",
      "Epoch 71/200\n",
      "3/3 - 0s - loss: 1.7408 - mse: 1.7408 - val_loss: 6.7450 - val_mse: 6.7450 - 29ms/epoch - 10ms/step\n",
      "Epoch 72/200\n",
      "3/3 - 0s - loss: 1.9013 - mse: 1.9013 - val_loss: 6.7105 - val_mse: 6.7105 - 29ms/epoch - 10ms/step\n",
      "Epoch 73/200\n",
      "3/3 - 0s - loss: 1.6222 - mse: 1.6222 - val_loss: 6.6891 - val_mse: 6.6891 - 29ms/epoch - 10ms/step\n",
      "Epoch 74/200\n",
      "3/3 - 0s - loss: 1.7213 - mse: 1.7213 - val_loss: 6.6322 - val_mse: 6.6322 - 33ms/epoch - 11ms/step\n",
      "Epoch 75/200\n",
      "3/3 - 0s - loss: 1.7003 - mse: 1.7003 - val_loss: 6.7662 - val_mse: 6.7662 - 29ms/epoch - 10ms/step\n",
      "Epoch 76/200\n",
      "3/3 - 0s - loss: 1.9938 - mse: 1.9938 - val_loss: 6.8419 - val_mse: 6.8419 - 30ms/epoch - 10ms/step\n",
      "Epoch 77/200\n",
      "3/3 - 0s - loss: 1.9368 - mse: 1.9368 - val_loss: 6.6742 - val_mse: 6.6742 - 29ms/epoch - 10ms/step\n",
      "Epoch 78/200\n",
      "3/3 - 0s - loss: 2.0340 - mse: 2.0340 - val_loss: 6.5862 - val_mse: 6.5862 - 30ms/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "3/3 - 0s - loss: 1.7972 - mse: 1.7972 - val_loss: 6.4690 - val_mse: 6.4690 - 30ms/epoch - 10ms/step\n",
      "Epoch 80/200\n",
      "3/3 - 0s - loss: 1.7347 - mse: 1.7347 - val_loss: 6.4773 - val_mse: 6.4773 - 30ms/epoch - 10ms/step\n",
      "Epoch 81/200\n",
      "3/3 - 0s - loss: 1.8892 - mse: 1.8892 - val_loss: 6.5323 - val_mse: 6.5323 - 29ms/epoch - 10ms/step\n",
      "Epoch 82/200\n",
      "3/3 - 0s - loss: 2.0465 - mse: 2.0465 - val_loss: 6.6022 - val_mse: 6.6022 - 29ms/epoch - 10ms/step\n",
      "Epoch 83/200\n",
      "3/3 - 0s - loss: 1.8938 - mse: 1.8938 - val_loss: 6.4226 - val_mse: 6.4226 - 28ms/epoch - 9ms/step\n",
      "Epoch 84/200\n",
      "3/3 - 0s - loss: 1.7882 - mse: 1.7882 - val_loss: 6.3447 - val_mse: 6.3447 - 31ms/epoch - 10ms/step\n",
      "Epoch 85/200\n",
      "3/3 - 0s - loss: 1.8548 - mse: 1.8548 - val_loss: 6.4161 - val_mse: 6.4161 - 29ms/epoch - 10ms/step\n",
      "Epoch 86/200\n",
      "3/3 - 0s - loss: 1.7737 - mse: 1.7737 - val_loss: 6.4914 - val_mse: 6.4914 - 28ms/epoch - 9ms/step\n",
      "Epoch 87/200\n",
      "3/3 - 0s - loss: 1.7536 - mse: 1.7536 - val_loss: 6.5369 - val_mse: 6.5369 - 28ms/epoch - 9ms/step\n",
      "Epoch 88/200\n",
      "3/3 - 0s - loss: 2.0590 - mse: 2.0590 - val_loss: 6.5918 - val_mse: 6.5918 - 28ms/epoch - 9ms/step\n",
      "Epoch 89/200\n",
      "3/3 - 0s - loss: 2.1565 - mse: 2.1565 - val_loss: 6.6546 - val_mse: 6.6546 - 29ms/epoch - 10ms/step\n",
      "Epoch 90/200\n",
      "3/3 - 0s - loss: 1.6950 - mse: 1.6950 - val_loss: 6.6516 - val_mse: 6.6516 - 32ms/epoch - 11ms/step\n",
      "Epoch 91/200\n",
      "3/3 - 0s - loss: 1.6937 - mse: 1.6937 - val_loss: 6.5678 - val_mse: 6.5678 - 29ms/epoch - 10ms/step\n",
      "Epoch 92/200\n",
      "3/3 - 0s - loss: 1.9012 - mse: 1.9012 - val_loss: 6.4388 - val_mse: 6.4388 - 29ms/epoch - 10ms/step\n",
      "Epoch 93/200\n",
      "3/3 - 0s - loss: 1.6230 - mse: 1.6230 - val_loss: 6.3290 - val_mse: 6.3290 - 32ms/epoch - 11ms/step\n",
      "Epoch 94/200\n",
      "3/3 - 0s - loss: 1.6837 - mse: 1.6837 - val_loss: 6.3513 - val_mse: 6.3513 - 31ms/epoch - 10ms/step\n",
      "Epoch 95/200\n",
      "3/3 - 0s - loss: 1.7117 - mse: 1.7117 - val_loss: 6.3475 - val_mse: 6.3475 - 29ms/epoch - 10ms/step\n",
      "Epoch 96/200\n",
      "3/3 - 0s - loss: 1.5780 - mse: 1.5780 - val_loss: 6.3118 - val_mse: 6.3118 - 32ms/epoch - 11ms/step\n",
      "Epoch 97/200\n",
      "3/3 - 0s - loss: 1.6226 - mse: 1.6226 - val_loss: 6.3048 - val_mse: 6.3048 - 32ms/epoch - 11ms/step\n",
      "Epoch 98/200\n",
      "3/3 - 0s - loss: 1.5406 - mse: 1.5406 - val_loss: 6.4800 - val_mse: 6.4800 - 29ms/epoch - 10ms/step\n",
      "Epoch 99/200\n",
      "3/3 - 0s - loss: 1.9949 - mse: 1.9949 - val_loss: 6.5998 - val_mse: 6.5998 - 29ms/epoch - 10ms/step\n",
      "Epoch 100/200\n",
      "3/3 - 0s - loss: 1.6713 - mse: 1.6713 - val_loss: 6.6311 - val_mse: 6.6311 - 28ms/epoch - 9ms/step\n",
      "Epoch 101/200\n",
      "3/3 - 0s - loss: 1.9078 - mse: 1.9078 - val_loss: 6.6111 - val_mse: 6.6111 - 30ms/epoch - 10ms/step\n",
      "Epoch 102/200\n",
      "3/3 - 0s - loss: 1.5679 - mse: 1.5679 - val_loss: 6.6146 - val_mse: 6.6146 - 30ms/epoch - 10ms/step\n",
      "Epoch 103/200\n",
      "3/3 - 0s - loss: 1.6677 - mse: 1.6677 - val_loss: 6.5283 - val_mse: 6.5283 - 29ms/epoch - 10ms/step\n",
      "Epoch 104/200\n",
      "3/3 - 0s - loss: 1.4595 - mse: 1.4595 - val_loss: 6.3413 - val_mse: 6.3413 - 30ms/epoch - 10ms/step\n",
      "Epoch 105/200\n",
      "3/3 - 0s - loss: 1.5584 - mse: 1.5584 - val_loss: 6.2476 - val_mse: 6.2476 - 33ms/epoch - 11ms/step\n",
      "Epoch 106/200\n",
      "3/3 - 0s - loss: 1.5883 - mse: 1.5883 - val_loss: 6.2526 - val_mse: 6.2526 - 29ms/epoch - 10ms/step\n",
      "Epoch 107/200\n",
      "3/3 - 0s - loss: 2.0164 - mse: 2.0164 - val_loss: 6.3552 - val_mse: 6.3552 - 30ms/epoch - 10ms/step\n",
      "Epoch 108/200\n",
      "3/3 - 0s - loss: 1.5725 - mse: 1.5725 - val_loss: 6.5252 - val_mse: 6.5252 - 29ms/epoch - 10ms/step\n",
      "Epoch 109/200\n",
      "3/3 - 0s - loss: 1.6143 - mse: 1.6143 - val_loss: 6.5220 - val_mse: 6.5220 - 29ms/epoch - 10ms/step\n",
      "Epoch 110/200\n",
      "3/3 - 0s - loss: 1.4324 - mse: 1.4324 - val_loss: 6.4286 - val_mse: 6.4286 - 30ms/epoch - 10ms/step\n",
      "Epoch 111/200\n",
      "3/3 - 0s - loss: 1.5429 - mse: 1.5429 - val_loss: 6.3808 - val_mse: 6.3808 - 29ms/epoch - 10ms/step\n",
      "Epoch 112/200\n",
      "3/3 - 0s - loss: 1.6986 - mse: 1.6986 - val_loss: 6.4270 - val_mse: 6.4270 - 30ms/epoch - 10ms/step\n",
      "Epoch 113/200\n",
      "3/3 - 0s - loss: 1.6677 - mse: 1.6677 - val_loss: 6.4881 - val_mse: 6.4881 - 30ms/epoch - 10ms/step\n",
      "Epoch 114/200\n",
      "3/3 - 0s - loss: 1.6707 - mse: 1.6707 - val_loss: 6.5069 - val_mse: 6.5069 - 30ms/epoch - 10ms/step\n",
      "Epoch 115/200\n",
      "3/3 - 0s - loss: 1.5610 - mse: 1.5610 - val_loss: 6.4757 - val_mse: 6.4757 - 30ms/epoch - 10ms/step\n",
      "Epoch 116/200\n",
      "3/3 - 0s - loss: 1.6308 - mse: 1.6308 - val_loss: 6.4948 - val_mse: 6.4948 - 30ms/epoch - 10ms/step\n",
      "Epoch 117/200\n",
      "3/3 - 0s - loss: 1.4465 - mse: 1.4465 - val_loss: 6.6237 - val_mse: 6.6237 - 30ms/epoch - 10ms/step\n",
      "Epoch 118/200\n",
      "3/3 - 0s - loss: 1.4014 - mse: 1.4014 - val_loss: 6.6149 - val_mse: 6.6149 - 30ms/epoch - 10ms/step\n",
      "Epoch 119/200\n",
      "3/3 - 0s - loss: 1.7692 - mse: 1.7692 - val_loss: 6.6808 - val_mse: 6.6808 - 31ms/epoch - 10ms/step\n",
      "Epoch 120/200\n",
      "3/3 - 0s - loss: 1.4657 - mse: 1.4657 - val_loss: 6.7974 - val_mse: 6.7974 - 30ms/epoch - 10ms/step\n",
      "Epoch 121/200\n",
      "3/3 - 0s - loss: 1.6269 - mse: 1.6269 - val_loss: 6.7195 - val_mse: 6.7195 - 30ms/epoch - 10ms/step\n",
      "Epoch 122/200\n",
      "3/3 - 0s - loss: 1.6079 - mse: 1.6079 - val_loss: 6.6531 - val_mse: 6.6531 - 31ms/epoch - 10ms/step\n",
      "Epoch 123/200\n",
      "3/3 - 0s - loss: 1.5402 - mse: 1.5402 - val_loss: 6.6049 - val_mse: 6.6049 - 30ms/epoch - 10ms/step\n",
      "Epoch 124/200\n",
      "3/3 - 0s - loss: 1.5855 - mse: 1.5855 - val_loss: 6.5331 - val_mse: 6.5331 - 30ms/epoch - 10ms/step\n",
      "Epoch 125/200\n",
      "3/3 - 0s - loss: 1.4089 - mse: 1.4089 - val_loss: 6.5280 - val_mse: 6.5280 - 29ms/epoch - 10ms/step\n",
      "Epoch 126/200\n",
      "3/3 - 0s - loss: 1.4529 - mse: 1.4529 - val_loss: 6.5415 - val_mse: 6.5415 - 29ms/epoch - 10ms/step\n",
      "Epoch 127/200\n",
      "3/3 - 0s - loss: 1.5046 - mse: 1.5046 - val_loss: 6.5492 - val_mse: 6.5492 - 30ms/epoch - 10ms/step\n",
      "Epoch 128/200\n",
      "3/3 - 0s - loss: 1.4875 - mse: 1.4875 - val_loss: 6.5192 - val_mse: 6.5192 - 31ms/epoch - 10ms/step\n",
      "Epoch 129/200\n",
      "3/3 - 0s - loss: 1.3947 - mse: 1.3947 - val_loss: 6.4914 - val_mse: 6.4914 - 29ms/epoch - 10ms/step\n",
      "Epoch 130/200\n",
      "3/3 - 0s - loss: 1.5579 - mse: 1.5579 - val_loss: 6.4150 - val_mse: 6.4150 - 30ms/epoch - 10ms/step\n",
      "Epoch 131/200\n",
      "3/3 - 0s - loss: 1.4950 - mse: 1.4950 - val_loss: 6.3409 - val_mse: 6.3409 - 30ms/epoch - 10ms/step\n",
      "Epoch 132/200\n",
      "3/3 - 0s - loss: 1.4260 - mse: 1.4260 - val_loss: 6.3305 - val_mse: 6.3305 - 30ms/epoch - 10ms/step\n",
      "Epoch 133/200\n",
      "3/3 - 0s - loss: 1.4204 - mse: 1.4204 - val_loss: 6.3256 - val_mse: 6.3256 - 29ms/epoch - 10ms/step\n",
      "Epoch 134/200\n",
      "3/3 - 0s - loss: 1.5510 - mse: 1.5510 - val_loss: 6.3774 - val_mse: 6.3774 - 29ms/epoch - 10ms/step\n",
      "Epoch 135/200\n",
      "3/3 - 0s - loss: 1.5634 - mse: 1.5634 - val_loss: 6.3509 - val_mse: 6.3509 - 30ms/epoch - 10ms/step\n",
      "Epoch 136/200\n",
      "3/3 - 0s - loss: 1.7507 - mse: 1.7507 - val_loss: 6.3234 - val_mse: 6.3234 - 30ms/epoch - 10ms/step\n",
      "Epoch 137/200\n",
      "3/3 - 0s - loss: 1.5632 - mse: 1.5632 - val_loss: 6.2731 - val_mse: 6.2731 - 29ms/epoch - 10ms/step\n",
      "Epoch 138/200\n",
      "3/3 - 0s - loss: 1.4397 - mse: 1.4397 - val_loss: 6.2263 - val_mse: 6.2263 - 33ms/epoch - 11ms/step\n",
      "Epoch 139/200\n",
      "3/3 - 0s - loss: 1.4341 - mse: 1.4341 - val_loss: 6.2119 - val_mse: 6.2119 - 33ms/epoch - 11ms/step\n",
      "Epoch 140/200\n",
      "3/3 - 0s - loss: 1.4908 - mse: 1.4908 - val_loss: 6.2065 - val_mse: 6.2065 - 33ms/epoch - 11ms/step\n",
      "Epoch 141/200\n",
      "3/3 - 0s - loss: 1.5967 - mse: 1.5967 - val_loss: 6.2358 - val_mse: 6.2358 - 29ms/epoch - 10ms/step\n",
      "Epoch 142/200\n",
      "3/3 - 0s - loss: 1.3584 - mse: 1.3584 - val_loss: 6.3028 - val_mse: 6.3028 - 30ms/epoch - 10ms/step\n",
      "Epoch 143/200\n",
      "3/3 - 0s - loss: 1.4745 - mse: 1.4745 - val_loss: 6.3439 - val_mse: 6.3439 - 29ms/epoch - 10ms/step\n",
      "Epoch 144/200\n",
      "3/3 - 0s - loss: 1.5218 - mse: 1.5218 - val_loss: 6.3462 - val_mse: 6.3462 - 30ms/epoch - 10ms/step\n",
      "Epoch 145/200\n",
      "3/3 - 0s - loss: 1.6161 - mse: 1.6161 - val_loss: 6.4061 - val_mse: 6.4061 - 30ms/epoch - 10ms/step\n",
      "Epoch 146/200\n",
      "3/3 - 0s - loss: 1.5774 - mse: 1.5774 - val_loss: 6.5264 - val_mse: 6.5264 - 31ms/epoch - 10ms/step\n",
      "Epoch 147/200\n",
      "3/3 - 0s - loss: 1.5928 - mse: 1.5928 - val_loss: 6.5365 - val_mse: 6.5365 - 31ms/epoch - 10ms/step\n",
      "Epoch 148/200\n",
      "3/3 - 0s - loss: 1.3589 - mse: 1.3589 - val_loss: 6.5274 - val_mse: 6.5274 - 31ms/epoch - 10ms/step\n",
      "Epoch 149/200\n",
      "3/3 - 0s - loss: 1.5355 - mse: 1.5355 - val_loss: 6.5627 - val_mse: 6.5627 - 73ms/epoch - 24ms/step\n",
      "Epoch 150/200\n",
      "3/3 - 0s - loss: 1.4830 - mse: 1.4830 - val_loss: 6.6526 - val_mse: 6.6526 - 33ms/epoch - 11ms/step\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.5015 - mse: 1.5015 - val_loss: 6.6744 - val_mse: 6.6744 - 30ms/epoch - 10ms/step\n",
      "Epoch 152/200\n",
      "3/3 - 0s - loss: 1.7032 - mse: 1.7032 - val_loss: 6.6407 - val_mse: 6.6407 - 30ms/epoch - 10ms/step\n",
      "Epoch 153/200\n",
      "3/3 - 0s - loss: 1.2373 - mse: 1.2373 - val_loss: 6.6577 - val_mse: 6.6577 - 28ms/epoch - 9ms/step\n",
      "Epoch 154/200\n",
      "3/3 - 0s - loss: 1.9951 - mse: 1.9951 - val_loss: 6.4834 - val_mse: 6.4834 - 29ms/epoch - 10ms/step\n",
      "Epoch 155/200\n",
      "3/3 - 0s - loss: 1.2548 - mse: 1.2548 - val_loss: 6.3710 - val_mse: 6.3710 - 30ms/epoch - 10ms/step\n",
      "Epoch 156/200\n",
      "3/3 - 0s - loss: 1.4765 - mse: 1.4765 - val_loss: 6.3092 - val_mse: 6.3092 - 29ms/epoch - 10ms/step\n",
      "Epoch 157/200\n",
      "3/3 - 0s - loss: 1.3147 - mse: 1.3147 - val_loss: 6.4038 - val_mse: 6.4038 - 31ms/epoch - 10ms/step\n",
      "Epoch 158/200\n",
      "3/3 - 0s - loss: 1.5428 - mse: 1.5428 - val_loss: 6.5202 - val_mse: 6.5202 - 29ms/epoch - 10ms/step\n",
      "Epoch 159/200\n",
      "3/3 - 0s - loss: 1.3155 - mse: 1.3155 - val_loss: 6.6138 - val_mse: 6.6138 - 30ms/epoch - 10ms/step\n",
      "Epoch 160/200\n",
      "3/3 - 0s - loss: 1.4149 - mse: 1.4149 - val_loss: 6.5218 - val_mse: 6.5218 - 28ms/epoch - 9ms/step\n",
      "Epoch 161/200\n",
      "3/3 - 0s - loss: 1.4454 - mse: 1.4454 - val_loss: 6.4263 - val_mse: 6.4263 - 32ms/epoch - 11ms/step\n",
      "Epoch 162/200\n",
      "3/3 - 0s - loss: 1.7724 - mse: 1.7724 - val_loss: 6.4048 - val_mse: 6.4048 - 29ms/epoch - 10ms/step\n",
      "Epoch 163/200\n",
      "3/3 - 0s - loss: 1.3060 - mse: 1.3060 - val_loss: 6.4208 - val_mse: 6.4208 - 29ms/epoch - 10ms/step\n",
      "Epoch 164/200\n",
      "3/3 - 0s - loss: 1.4970 - mse: 1.4970 - val_loss: 6.5193 - val_mse: 6.5193 - 29ms/epoch - 10ms/step\n",
      "Epoch 165/200\n",
      "3/3 - 0s - loss: 1.3950 - mse: 1.3950 - val_loss: 6.5871 - val_mse: 6.5871 - 29ms/epoch - 10ms/step\n",
      "Epoch 166/200\n",
      "3/3 - 0s - loss: 1.4434 - mse: 1.4434 - val_loss: 6.5404 - val_mse: 6.5404 - 29ms/epoch - 10ms/step\n",
      "Epoch 167/200\n",
      "3/3 - 0s - loss: 1.3205 - mse: 1.3205 - val_loss: 6.5087 - val_mse: 6.5087 - 29ms/epoch - 10ms/step\n",
      "Epoch 168/200\n",
      "3/3 - 0s - loss: 1.3899 - mse: 1.3899 - val_loss: 6.4948 - val_mse: 6.4948 - 29ms/epoch - 10ms/step\n",
      "Epoch 169/200\n",
      "3/3 - 0s - loss: 1.3076 - mse: 1.3076 - val_loss: 6.4468 - val_mse: 6.4468 - 29ms/epoch - 10ms/step\n",
      "Epoch 170/200\n",
      "3/3 - 0s - loss: 1.4001 - mse: 1.4001 - val_loss: 6.4692 - val_mse: 6.4692 - 32ms/epoch - 11ms/step\n",
      "Epoch 171/200\n",
      "3/3 - 0s - loss: 1.3364 - mse: 1.3364 - val_loss: 6.6131 - val_mse: 6.6131 - 31ms/epoch - 10ms/step\n",
      "Epoch 172/200\n",
      "3/3 - 0s - loss: 1.3154 - mse: 1.3154 - val_loss: 6.8173 - val_mse: 6.8173 - 30ms/epoch - 10ms/step\n",
      "Epoch 173/200\n",
      "3/3 - 0s - loss: 1.4749 - mse: 1.4749 - val_loss: 6.7728 - val_mse: 6.7728 - 30ms/epoch - 10ms/step\n",
      "Epoch 174/200\n",
      "3/3 - 0s - loss: 1.6312 - mse: 1.6312 - val_loss: 6.6015 - val_mse: 6.6015 - 29ms/epoch - 10ms/step\n",
      "Epoch 175/200\n",
      "3/3 - 0s - loss: 1.2432 - mse: 1.2432 - val_loss: 6.5316 - val_mse: 6.5316 - 30ms/epoch - 10ms/step\n",
      "Epoch 176/200\n",
      "3/3 - 0s - loss: 1.4239 - mse: 1.4239 - val_loss: 6.5452 - val_mse: 6.5452 - 29ms/epoch - 10ms/step\n",
      "Epoch 177/200\n",
      "3/3 - 0s - loss: 1.2425 - mse: 1.2425 - val_loss: 6.5299 - val_mse: 6.5299 - 29ms/epoch - 10ms/step\n",
      "Epoch 178/200\n",
      "3/3 - 0s - loss: 1.3497 - mse: 1.3497 - val_loss: 6.5427 - val_mse: 6.5427 - 30ms/epoch - 10ms/step\n",
      "Epoch 179/200\n",
      "3/3 - 0s - loss: 1.1931 - mse: 1.1931 - val_loss: 6.6410 - val_mse: 6.6410 - 30ms/epoch - 10ms/step\n",
      "Epoch 180/200\n",
      "3/3 - 0s - loss: 1.8344 - mse: 1.8344 - val_loss: 6.8441 - val_mse: 6.8441 - 29ms/epoch - 10ms/step\n",
      "Epoch 181/200\n",
      "3/3 - 0s - loss: 1.3097 - mse: 1.3097 - val_loss: 6.8801 - val_mse: 6.8801 - 30ms/epoch - 10ms/step\n",
      "Epoch 182/200\n",
      "3/3 - 0s - loss: 1.1929 - mse: 1.1929 - val_loss: 6.7484 - val_mse: 6.7484 - 30ms/epoch - 10ms/step\n",
      "Epoch 183/200\n",
      "3/3 - 0s - loss: 1.4029 - mse: 1.4029 - val_loss: 6.7984 - val_mse: 6.7984 - 30ms/epoch - 10ms/step\n",
      "Epoch 184/200\n",
      "3/3 - 0s - loss: 1.2094 - mse: 1.2094 - val_loss: 6.6897 - val_mse: 6.6897 - 29ms/epoch - 10ms/step\n",
      "Epoch 185/200\n",
      "3/3 - 0s - loss: 1.2335 - mse: 1.2335 - val_loss: 6.6821 - val_mse: 6.6821 - 29ms/epoch - 10ms/step\n",
      "Epoch 186/200\n",
      "3/3 - 0s - loss: 1.2765 - mse: 1.2765 - val_loss: 6.7796 - val_mse: 6.7796 - 30ms/epoch - 10ms/step\n",
      "Epoch 187/200\n",
      "3/3 - 0s - loss: 1.4818 - mse: 1.4818 - val_loss: 6.7795 - val_mse: 6.7795 - 29ms/epoch - 10ms/step\n",
      "Epoch 188/200\n",
      "3/3 - 0s - loss: 1.2257 - mse: 1.2257 - val_loss: 6.6372 - val_mse: 6.6372 - 29ms/epoch - 10ms/step\n",
      "Epoch 189/200\n",
      "3/3 - 0s - loss: 1.2694 - mse: 1.2694 - val_loss: 6.7888 - val_mse: 6.7888 - 29ms/epoch - 10ms/step\n",
      "Epoch 190/200\n",
      "3/3 - 0s - loss: 1.2125 - mse: 1.2125 - val_loss: 6.9317 - val_mse: 6.9317 - 31ms/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:27:26.003280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 64\n",
    "layer_2_units = 64\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = True\n",
    "\n",
    "# Build and compile model\n",
    "model = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"neural_network-64_64_init_bn\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f4fe3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7727d4c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:17:30.912410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 17.8342 - mse: 17.8342 - val_loss: 15.7452 - val_mse: 15.7452 - 473ms/epoch - 158ms/step\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 8.5652 - mse: 8.5652 - val_loss: 8.9011 - val_mse: 8.9011 - 26ms/epoch - 9ms/step\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 7.1895 - mse: 7.1895 - val_loss: 9.5617 - val_mse: 9.5617 - 32ms/epoch - 11ms/step\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 8.4689 - mse: 8.4689 - val_loss: 7.9956 - val_mse: 7.9956 - 29ms/epoch - 10ms/step\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 6.6286 - mse: 6.6286 - val_loss: 7.1548 - val_mse: 7.1548 - 31ms/epoch - 10ms/step\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 4.9607 - mse: 4.9607 - val_loss: 7.5189 - val_mse: 7.5189 - 27ms/epoch - 9ms/step\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:17:31.221679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 4.7402 - mse: 4.7402 - val_loss: 7.7494 - val_mse: 7.7494 - 25ms/epoch - 8ms/step\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 4.5325 - mse: 4.5325 - val_loss: 7.2399 - val_mse: 7.2399 - 27ms/epoch - 9ms/step\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 4.2819 - mse: 4.2819 - val_loss: 6.5928 - val_mse: 6.5928 - 28ms/epoch - 9ms/step\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 4.2913 - mse: 4.2913 - val_loss: 6.4684 - val_mse: 6.4684 - 27ms/epoch - 9ms/step\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 4.0944 - mse: 4.0944 - val_loss: 6.7066 - val_mse: 6.7066 - 25ms/epoch - 8ms/step\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 3.9838 - mse: 3.9838 - val_loss: 6.9439 - val_mse: 6.9439 - 27ms/epoch - 9ms/step\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 3.9000 - mse: 3.9000 - val_loss: 6.5091 - val_mse: 6.5091 - 26ms/epoch - 9ms/step\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 3.8281 - mse: 3.8281 - val_loss: 6.1909 - val_mse: 6.1909 - 27ms/epoch - 9ms/step\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 3.7931 - mse: 3.7931 - val_loss: 6.1722 - val_mse: 6.1722 - 29ms/epoch - 10ms/step\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 3.7414 - mse: 3.7414 - val_loss: 6.3316 - val_mse: 6.3316 - 27ms/epoch - 9ms/step\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 3.6867 - mse: 3.6867 - val_loss: 6.4992 - val_mse: 6.4992 - 27ms/epoch - 9ms/step\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 3.6917 - mse: 3.6917 - val_loss: 6.5474 - val_mse: 6.5474 - 33ms/epoch - 11ms/step\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 3.6197 - mse: 3.6197 - val_loss: 6.2862 - val_mse: 6.2862 - 26ms/epoch - 9ms/step\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 3.6016 - mse: 3.6016 - val_loss: 6.2161 - val_mse: 6.2161 - 27ms/epoch - 9ms/step\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 3.5392 - mse: 3.5392 - val_loss: 6.4006 - val_mse: 6.4006 - 26ms/epoch - 9ms/step\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 3.5070 - mse: 3.5070 - val_loss: 6.5479 - val_mse: 6.5479 - 26ms/epoch - 9ms/step\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 3.4772 - mse: 3.4772 - val_loss: 6.4588 - val_mse: 6.4588 - 26ms/epoch - 9ms/step\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 3.4255 - mse: 3.4255 - val_loss: 6.3874 - val_mse: 6.3874 - 27ms/epoch - 9ms/step\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 3.4186 - mse: 3.4186 - val_loss: 6.4082 - val_mse: 6.4082 - 29ms/epoch - 10ms/step\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 3.3723 - mse: 3.3723 - val_loss: 6.6458 - val_mse: 6.6458 - 26ms/epoch - 9ms/step\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 3.3473 - mse: 3.3473 - val_loss: 6.8225 - val_mse: 6.8225 - 27ms/epoch - 9ms/step\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 3.3223 - mse: 3.3223 - val_loss: 6.8267 - val_mse: 6.8267 - 26ms/epoch - 9ms/step\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 3.3047 - mse: 3.3047 - val_loss: 6.7014 - val_mse: 6.7014 - 28ms/epoch - 9ms/step\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 3.2876 - mse: 3.2876 - val_loss: 6.7880 - val_mse: 6.7880 - 27ms/epoch - 9ms/step\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 3.2546 - mse: 3.2546 - val_loss: 7.0134 - val_mse: 7.0134 - 25ms/epoch - 8ms/step\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 3.2265 - mse: 3.2265 - val_loss: 7.0135 - val_mse: 7.0135 - 26ms/epoch - 9ms/step\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 3.1839 - mse: 3.1839 - val_loss: 6.9904 - val_mse: 6.9904 - 27ms/epoch - 9ms/step\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 3.1794 - mse: 3.1794 - val_loss: 6.9225 - val_mse: 6.9225 - 26ms/epoch - 9ms/step\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 3.1607 - mse: 3.1607 - val_loss: 7.0763 - val_mse: 7.0763 - 26ms/epoch - 9ms/step\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 3.1349 - mse: 3.1349 - val_loss: 7.0587 - val_mse: 7.0587 - 27ms/epoch - 9ms/step\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 3.0915 - mse: 3.0915 - val_loss: 7.1620 - val_mse: 7.1620 - 28ms/epoch - 9ms/step\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 3.0989 - mse: 3.0989 - val_loss: 7.3661 - val_mse: 7.3661 - 27ms/epoch - 9ms/step\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 3.0588 - mse: 3.0588 - val_loss: 7.1803 - val_mse: 7.1803 - 27ms/epoch - 9ms/step\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 3.0208 - mse: 3.0208 - val_loss: 7.0297 - val_mse: 7.0297 - 28ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:17:32.398771: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 64\n",
    "layer_2_units = 128\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = False\n",
    "\n",
    "# Build and compile model\n",
    "model = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"neural_network-64_128\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38920cbc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c87439ae",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 - 0s - loss: 23.8950 - mse: 23.8950 - val_loss: 10.8442 - val_mse: 10.8442 - 304ms/epoch - 101ms/step\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:18:02.003547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 14:18:02.156757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 8.5613 - mse: 8.5613 - val_loss: 12.7788 - val_mse: 12.7788 - 26ms/epoch - 9ms/step\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 11.5893 - mse: 11.5893 - val_loss: 8.3671 - val_mse: 8.3671 - 30ms/epoch - 10ms/step\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 6.5829 - mse: 6.5829 - val_loss: 8.6595 - val_mse: 8.6595 - 28ms/epoch - 9ms/step\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 5.6135 - mse: 5.6135 - val_loss: 9.5364 - val_mse: 9.5364 - 27ms/epoch - 9ms/step\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 5.4670 - mse: 5.4670 - val_loss: 8.0188 - val_mse: 8.0188 - 33ms/epoch - 11ms/step\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 4.3561 - mse: 4.3561 - val_loss: 6.2787 - val_mse: 6.2787 - 27ms/epoch - 9ms/step\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 5.0913 - mse: 5.0913 - val_loss: 6.0576 - val_mse: 6.0576 - 29ms/epoch - 10ms/step\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 4.5439 - mse: 4.5439 - val_loss: 6.4141 - val_mse: 6.4141 - 27ms/epoch - 9ms/step\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 3.8786 - mse: 3.8786 - val_loss: 7.2833 - val_mse: 7.2833 - 25ms/epoch - 8ms/step\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 4.1007 - mse: 4.1007 - val_loss: 7.1411 - val_mse: 7.1411 - 24ms/epoch - 8ms/step\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 3.9448 - mse: 3.9448 - val_loss: 6.3254 - val_mse: 6.3254 - 25ms/epoch - 8ms/step\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 3.7172 - mse: 3.7172 - val_loss: 5.9036 - val_mse: 5.9036 - 27ms/epoch - 9ms/step\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 3.7551 - mse: 3.7551 - val_loss: 5.9649 - val_mse: 5.9649 - 26ms/epoch - 9ms/step\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 3.6435 - mse: 3.6435 - val_loss: 6.4302 - val_mse: 6.4302 - 25ms/epoch - 8ms/step\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 3.5740 - mse: 3.5740 - val_loss: 6.8280 - val_mse: 6.8280 - 26ms/epoch - 9ms/step\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 3.5401 - mse: 3.5401 - val_loss: 6.6116 - val_mse: 6.6116 - 26ms/epoch - 9ms/step\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 3.4210 - mse: 3.4210 - val_loss: 6.5624 - val_mse: 6.5624 - 24ms/epoch - 8ms/step\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 3.4059 - mse: 3.4059 - val_loss: 6.7108 - val_mse: 6.7108 - 24ms/epoch - 8ms/step\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 3.3226 - mse: 3.3226 - val_loss: 6.6990 - val_mse: 6.6990 - 26ms/epoch - 9ms/step\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 3.3016 - mse: 3.3016 - val_loss: 6.6752 - val_mse: 6.6752 - 25ms/epoch - 8ms/step\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 3.2996 - mse: 3.2996 - val_loss: 6.8500 - val_mse: 6.8500 - 30ms/epoch - 10ms/step\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 3.2448 - mse: 3.2448 - val_loss: 6.8784 - val_mse: 6.8784 - 26ms/epoch - 9ms/step\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 3.2371 - mse: 3.2371 - val_loss: 6.8568 - val_mse: 6.8568 - 26ms/epoch - 9ms/step\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 3.1666 - mse: 3.1666 - val_loss: 7.0798 - val_mse: 7.0798 - 28ms/epoch - 9ms/step\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 3.2121 - mse: 3.2121 - val_loss: 7.2594 - val_mse: 7.2594 - 25ms/epoch - 8ms/step\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 3.1549 - mse: 3.1549 - val_loss: 6.9808 - val_mse: 6.9808 - 25ms/epoch - 8ms/step\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 3.0872 - mse: 3.0872 - val_loss: 6.8253 - val_mse: 6.8253 - 25ms/epoch - 8ms/step\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 3.1105 - mse: 3.1105 - val_loss: 6.8588 - val_mse: 6.8588 - 27ms/epoch - 9ms/step\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 3.0747 - mse: 3.0747 - val_loss: 7.0226 - val_mse: 7.0226 - 25ms/epoch - 8ms/step\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 3.0505 - mse: 3.0505 - val_loss: 7.3639 - val_mse: 7.3639 - 26ms/epoch - 9ms/step\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 3.0561 - mse: 3.0561 - val_loss: 7.2318 - val_mse: 7.2318 - 25ms/epoch - 8ms/step\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 3.0154 - mse: 3.0154 - val_loss: 7.1039 - val_mse: 7.1039 - 26ms/epoch - 9ms/step\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 3.0302 - mse: 3.0302 - val_loss: 6.9231 - val_mse: 6.9231 - 26ms/epoch - 9ms/step\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 3.0156 - mse: 3.0156 - val_loss: 7.0766 - val_mse: 7.0766 - 25ms/epoch - 8ms/step\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 2.9487 - mse: 2.9487 - val_loss: 7.1018 - val_mse: 7.1018 - 26ms/epoch - 9ms/step\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 2.9336 - mse: 2.9336 - val_loss: 7.1185 - val_mse: 7.1185 - 26ms/epoch - 9ms/step\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 2.9572 - mse: 2.9572 - val_loss: 7.1930 - val_mse: 7.1930 - 26ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:18:03.248310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 128\n",
    "layer_2_units = 128\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = False\n",
    "\n",
    "# Build and compile model\n",
    "model = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"neural_network-128_128\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1b590",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68c4a130",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 - 0s - loss: 15.8271 - mse: 15.8271 - val_loss: 14.0402 - val_mse: 14.0402 - 300ms/epoch - 100ms/step\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:21:10.766739: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 14:21:10.909815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 9.4405 - mse: 9.4405 - val_loss: 11.3053 - val_mse: 11.3053 - 32ms/epoch - 11ms/step\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 9.7488 - mse: 9.7488 - val_loss: 11.2969 - val_mse: 11.2969 - 30ms/epoch - 10ms/step\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 9.4060 - mse: 9.4060 - val_loss: 9.5024 - val_mse: 9.5024 - 30ms/epoch - 10ms/step\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 7.1661 - mse: 7.1661 - val_loss: 9.2853 - val_mse: 9.2853 - 30ms/epoch - 10ms/step\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 6.1443 - mse: 6.1443 - val_loss: 10.1248 - val_mse: 10.1248 - 27ms/epoch - 9ms/step\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 6.4616 - mse: 6.4616 - val_loss: 10.2217 - val_mse: 10.2217 - 26ms/epoch - 9ms/step\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 6.0023 - mse: 6.0023 - val_loss: 8.3824 - val_mse: 8.3824 - 34ms/epoch - 11ms/step\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 5.0441 - mse: 5.0441 - val_loss: 6.8960 - val_mse: 6.8960 - 29ms/epoch - 10ms/step\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 5.0697 - mse: 5.0697 - val_loss: 6.5076 - val_mse: 6.5076 - 30ms/epoch - 10ms/step\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 4.9405 - mse: 4.9405 - val_loss: 6.6557 - val_mse: 6.6557 - 26ms/epoch - 9ms/step\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 4.5127 - mse: 4.5127 - val_loss: 7.3069 - val_mse: 7.3069 - 25ms/epoch - 8ms/step\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 4.4343 - mse: 4.4343 - val_loss: 7.4440 - val_mse: 7.4440 - 27ms/epoch - 9ms/step\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 4.2924 - mse: 4.2924 - val_loss: 6.8104 - val_mse: 6.8104 - 27ms/epoch - 9ms/step\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 4.1183 - mse: 4.1183 - val_loss: 6.3944 - val_mse: 6.3944 - 28ms/epoch - 9ms/step\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 4.0065 - mse: 4.0065 - val_loss: 6.2976 - val_mse: 6.2976 - 27ms/epoch - 9ms/step\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 3.9538 - mse: 3.9538 - val_loss: 6.3750 - val_mse: 6.3750 - 26ms/epoch - 9ms/step\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 3.8127 - mse: 3.8127 - val_loss: 6.4029 - val_mse: 6.4029 - 24ms/epoch - 8ms/step\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 3.7544 - mse: 3.7544 - val_loss: 6.4830 - val_mse: 6.4830 - 25ms/epoch - 8ms/step\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 3.7536 - mse: 3.7536 - val_loss: 6.5003 - val_mse: 6.5003 - 24ms/epoch - 8ms/step\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 3.6677 - mse: 3.6677 - val_loss: 6.2654 - val_mse: 6.2654 - 26ms/epoch - 9ms/step\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 3.5928 - mse: 3.5928 - val_loss: 5.9883 - val_mse: 5.9883 - 29ms/epoch - 10ms/step\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 3.6578 - mse: 3.6578 - val_loss: 5.9186 - val_mse: 5.9186 - 28ms/epoch - 9ms/step\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 3.5946 - mse: 3.5946 - val_loss: 6.1759 - val_mse: 6.1759 - 34ms/epoch - 11ms/step\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 3.5373 - mse: 3.5373 - val_loss: 6.4019 - val_mse: 6.4019 - 24ms/epoch - 8ms/step\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 3.5303 - mse: 3.5303 - val_loss: 6.4334 - val_mse: 6.4334 - 26ms/epoch - 9ms/step\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 3.5024 - mse: 3.5024 - val_loss: 6.2229 - val_mse: 6.2229 - 27ms/epoch - 9ms/step\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 3.4513 - mse: 3.4513 - val_loss: 6.0727 - val_mse: 6.0727 - 26ms/epoch - 9ms/step\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 3.4896 - mse: 3.4896 - val_loss: 5.9802 - val_mse: 5.9802 - 26ms/epoch - 9ms/step\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 3.4419 - mse: 3.4419 - val_loss: 6.1482 - val_mse: 6.1482 - 26ms/epoch - 9ms/step\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 3.4904 - mse: 3.4904 - val_loss: 6.5326 - val_mse: 6.5326 - 29ms/epoch - 10ms/step\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 3.4650 - mse: 3.4650 - val_loss: 6.4620 - val_mse: 6.4620 - 25ms/epoch - 8ms/step\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 3.3752 - mse: 3.3752 - val_loss: 6.0990 - val_mse: 6.0990 - 26ms/epoch - 9ms/step\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 3.4441 - mse: 3.4441 - val_loss: 5.9337 - val_mse: 5.9337 - 25ms/epoch - 8ms/step\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 3.4542 - mse: 3.4542 - val_loss: 6.1228 - val_mse: 6.1228 - 28ms/epoch - 9ms/step\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 3.3355 - mse: 3.3355 - val_loss: 6.3595 - val_mse: 6.3595 - 26ms/epoch - 9ms/step\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 3.3068 - mse: 3.3068 - val_loss: 6.6666 - val_mse: 6.6666 - 24ms/epoch - 8ms/step\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 3.4093 - mse: 3.4093 - val_loss: 6.8004 - val_mse: 6.8004 - 25ms/epoch - 8ms/step\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 3.3462 - mse: 3.3462 - val_loss: 6.3978 - val_mse: 6.3978 - 26ms/epoch - 9ms/step\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 3.3516 - mse: 3.3516 - val_loss: 6.0218 - val_mse: 6.0218 - 24ms/epoch - 8ms/step\n",
      "Epoch 41/200\n",
      "3/3 - 0s - loss: 3.3759 - mse: 3.3759 - val_loss: 6.0521 - val_mse: 6.0521 - 24ms/epoch - 8ms/step\n",
      "Epoch 42/200\n",
      "3/3 - 0s - loss: 3.3264 - mse: 3.3264 - val_loss: 6.3742 - val_mse: 6.3742 - 24ms/epoch - 8ms/step\n",
      "Epoch 43/200\n",
      "3/3 - 0s - loss: 3.2674 - mse: 3.2674 - val_loss: 6.6347 - val_mse: 6.6347 - 25ms/epoch - 8ms/step\n",
      "Epoch 44/200\n",
      "3/3 - 0s - loss: 3.2677 - mse: 3.2677 - val_loss: 6.5812 - val_mse: 6.5812 - 25ms/epoch - 8ms/step\n",
      "Epoch 45/200\n",
      "3/3 - 0s - loss: 3.2343 - mse: 3.2343 - val_loss: 6.4257 - val_mse: 6.4257 - 25ms/epoch - 8ms/step\n",
      "Epoch 46/200\n",
      "3/3 - 0s - loss: 3.2231 - mse: 3.2231 - val_loss: 6.3662 - val_mse: 6.3662 - 24ms/epoch - 8ms/step\n",
      "Epoch 47/200\n",
      "3/3 - 0s - loss: 3.2127 - mse: 3.2127 - val_loss: 6.4158 - val_mse: 6.4158 - 25ms/epoch - 8ms/step\n",
      "Epoch 48/200\n",
      "3/3 - 0s - loss: 3.2051 - mse: 3.2051 - val_loss: 6.6010 - val_mse: 6.6010 - 25ms/epoch - 8ms/step\n",
      "Epoch 49/200\n",
      "3/3 - 0s - loss: 3.1878 - mse: 3.1878 - val_loss: 6.6435 - val_mse: 6.6435 - 25ms/epoch - 8ms/step\n",
      "Epoch 50/200\n",
      "3/3 - 0s - loss: 3.1952 - mse: 3.1952 - val_loss: 6.5084 - val_mse: 6.5084 - 25ms/epoch - 8ms/step\n",
      "Epoch 51/200\n",
      "3/3 - 0s - loss: 3.1630 - mse: 3.1630 - val_loss: 6.5230 - val_mse: 6.5230 - 25ms/epoch - 8ms/step\n",
      "Epoch 52/200\n",
      "3/3 - 0s - loss: 3.1543 - mse: 3.1543 - val_loss: 6.5153 - val_mse: 6.5153 - 25ms/epoch - 8ms/step\n",
      "Epoch 53/200\n",
      "3/3 - 0s - loss: 3.1397 - mse: 3.1397 - val_loss: 6.6412 - val_mse: 6.6412 - 27ms/epoch - 9ms/step\n",
      "Epoch 54/200\n",
      "3/3 - 0s - loss: 3.1361 - mse: 3.1361 - val_loss: 6.8546 - val_mse: 6.8546 - 25ms/epoch - 8ms/step\n",
      "Epoch 55/200\n",
      "3/3 - 0s - loss: 3.1775 - mse: 3.1775 - val_loss: 7.1158 - val_mse: 7.1158 - 26ms/epoch - 9ms/step\n",
      "Epoch 56/200\n",
      "3/3 - 0s - loss: 3.1560 - mse: 3.1560 - val_loss: 6.9594 - val_mse: 6.9594 - 28ms/epoch - 9ms/step\n",
      "Epoch 57/200\n",
      "3/3 - 0s - loss: 3.1250 - mse: 3.1250 - val_loss: 6.5955 - val_mse: 6.5955 - 24ms/epoch - 8ms/step\n",
      "Epoch 58/200\n",
      "3/3 - 0s - loss: 3.1250 - mse: 3.1250 - val_loss: 6.5701 - val_mse: 6.5701 - 26ms/epoch - 9ms/step\n",
      "Epoch 59/200\n",
      "3/3 - 0s - loss: 3.0987 - mse: 3.0987 - val_loss: 6.7989 - val_mse: 6.7989 - 27ms/epoch - 9ms/step\n",
      "Epoch 60/200\n",
      "3/3 - 0s - loss: 3.0682 - mse: 3.0682 - val_loss: 7.0536 - val_mse: 7.0536 - 26ms/epoch - 9ms/step\n",
      "Epoch 61/200\n",
      "3/3 - 0s - loss: 3.0724 - mse: 3.0724 - val_loss: 7.0103 - val_mse: 7.0103 - 27ms/epoch - 9ms/step\n",
      "Epoch 62/200\n",
      "3/3 - 0s - loss: 3.0451 - mse: 3.0451 - val_loss: 6.9593 - val_mse: 6.9593 - 27ms/epoch - 9ms/step\n",
      "Epoch 63/200\n",
      "3/3 - 0s - loss: 3.0487 - mse: 3.0487 - val_loss: 6.8420 - val_mse: 6.8420 - 25ms/epoch - 8ms/step\n",
      "Epoch 64/200\n",
      "3/3 - 0s - loss: 3.0170 - mse: 3.0170 - val_loss: 6.8013 - val_mse: 6.8013 - 26ms/epoch - 9ms/step\n",
      "Epoch 65/200\n",
      "3/3 - 0s - loss: 3.0430 - mse: 3.0430 - val_loss: 6.7538 - val_mse: 6.7538 - 26ms/epoch - 9ms/step\n",
      "Epoch 66/200\n",
      "3/3 - 0s - loss: 3.0290 - mse: 3.0290 - val_loss: 6.8163 - val_mse: 6.8163 - 28ms/epoch - 9ms/step\n",
      "Epoch 67/200\n",
      "3/3 - 0s - loss: 3.0192 - mse: 3.0192 - val_loss: 6.9330 - val_mse: 6.9330 - 27ms/epoch - 9ms/step\n",
      "Epoch 68/200\n",
      "3/3 - 0s - loss: 3.0064 - mse: 3.0064 - val_loss: 6.9729 - val_mse: 6.9729 - 27ms/epoch - 9ms/step\n",
      "Epoch 69/200\n",
      "3/3 - 0s - loss: 2.9728 - mse: 2.9728 - val_loss: 6.9405 - val_mse: 6.9405 - 27ms/epoch - 9ms/step\n",
      "Epoch 70/200\n",
      "3/3 - 0s - loss: 2.9640 - mse: 2.9640 - val_loss: 6.8776 - val_mse: 6.8776 - 25ms/epoch - 8ms/step\n",
      "Epoch 71/200\n",
      "3/3 - 0s - loss: 3.0050 - mse: 3.0050 - val_loss: 6.8414 - val_mse: 6.8414 - 26ms/epoch - 9ms/step\n",
      "Epoch 72/200\n",
      "3/3 - 0s - loss: 2.9553 - mse: 2.9553 - val_loss: 7.0455 - val_mse: 7.0455 - 25ms/epoch - 8ms/step\n",
      "Epoch 73/200\n",
      "3/3 - 0s - loss: 2.9500 - mse: 2.9500 - val_loss: 7.1208 - val_mse: 7.1208 - 28ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 14:21:12.995092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 32\n",
    "layer_2_units = 32\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = False,\n",
    "\n",
    "# Build and compile model\n",
    "model = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"neural_network-32_32\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2662a684",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network</td>\n",
       "      <td>2.043704</td>\n",
       "      <td>1.813406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64</td>\n",
       "      <td>2.065874</td>\n",
       "      <td>1.828010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64_init</td>\n",
       "      <td>2.096282</td>\n",
       "      <td>1.831205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_128</td>\n",
       "      <td>2.058027</td>\n",
       "      <td>1.868867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.969422</td>\n",
       "      <td>1.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64</td>\n",
       "      <td>2.011368</td>\n",
       "      <td>1.888757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-32_64</td>\n",
       "      <td>2.021202</td>\n",
       "      <td>1.914971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-128_128</td>\n",
       "      <td>2.032535</td>\n",
       "      <td>1.917668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-32_32</td>\n",
       "      <td>2.019506</td>\n",
       "      <td>2.041065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-32_32</td>\n",
       "      <td>1.998198</td>\n",
       "      <td>2.048241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64_init_bn</td>\n",
       "      <td>1.555074</td>\n",
       "      <td>2.178951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  train_rmse  test_rmse\n",
       "0                neural_network    2.043704   1.813406\n",
       "0          neural_network-64_64    2.065874   1.828010\n",
       "0     neural_network-64_64_init    2.096282   1.831205\n",
       "0         neural_network-64_128    2.058027   1.868867\n",
       "0                        linear    1.969422   1.888512\n",
       "0          neural_network-64_64    2.011368   1.888757\n",
       "0          neural_network-32_64    2.021202   1.914971\n",
       "0        neural_network-128_128    2.032535   1.917668\n",
       "0          neural_network-32_32    2.019506   2.041065\n",
       "0          neural_network-32_32    1.998198   2.048241\n",
       "0  neural_network-64_64_init_bn    1.555074   2.178951"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.sort_values(\"test_rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107f7a2",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b0a892e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f4cb7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params to compile model with\n",
    "fixed_params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': \"rmse\",  \n",
    "        'verbosity': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0763f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    \"\"\"\n",
    "    Wrapper function to work with Optuna trial objects, \n",
    "    enabling Hyperband hyperparameter search.\n",
    "    \"\"\"   \n",
    "    # Suggest hyperparams to test using Optuna trial object.\n",
    "    param = {**fixed_params,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 3000, step = 20),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.2, 0.99, step = 0.05),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.2, 0.99, step = 0.05),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 5000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 2000, step=5),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 10),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "    }\n",
    "    \n",
    "    # Create cv object\n",
    "    cv = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "    # Make empty array to store cv f1 scores in\n",
    "    cv_scores = np.empty(5)\n",
    "    \n",
    "    # Split into K train and validation sets and iterate through them\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        # Split into training and validation CV sets\n",
    "        X_train_cv, X_test_cv = X[train_idx], X[test_idx]\n",
    "        y_train_cv, y_test_cv = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Convert data to proper LGBM format\n",
    "        train_data = lgb.Dataset(X_train_cv, label = y_train_cv,\n",
    "                                 categorical_feature = [0,1,2,3,4,6,7,8])\n",
    "        val_data = lgb.Dataset(X_test_cv, label = y_test_cv, \n",
    "                               categorical_feature = [0,1,2,3,4,6,7,8],\n",
    "                              reference = train_data)\n",
    "        \n",
    "        # Make callbacks to prevent trialling hyperparams that are obviously bad\n",
    "        callbacks = [\n",
    "            LightGBMPruningCallback(trial, metric = \"rmse\"),\n",
    "                     # Callback to reduce model validation performance messages\n",
    "                    lgb.log_evaluation(period = 100),\n",
    "                     # Early stoppping to prevent overfitting training data\n",
    "                    lgb.early_stopping(100)]\n",
    "\n",
    "        # Training the model\n",
    "        model = lgb.train(params = param,  train_set = train_data,\n",
    "                          valid_sets = val_data,   \n",
    "                          callbacks = callbacks,\n",
    "                         )\n",
    "    \n",
    "        \n",
    "        # Get predictions\n",
    "        preds = model.predict(X_test_cv)\n",
    "        # Calculate RMSE\n",
    "        cv_scores[idx] = mean_squared_error(y_test_cv, preds, squared = False)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b780f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture my_study\n",
    "# Above line magic hides lengthy output, but stores into first_round if you want to look\n",
    "\n",
    "# Create Optuna study to do CV hyperparameter search\n",
    "study = optuna.create_study(direction = \"minimize\", # minimizing RMSE\n",
    "                            study_name = \"LGBM Classifier\",\n",
    "                           pruner=optuna.pruners.HyperbandPruner())\n",
    "func = lambda trial: objective(trial, X = X_train, y = y_train)\n",
    "study.optimize(func, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "46991062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0306908927013265"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8821ce4",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec4994",
   "metadata": {},
   "source": [
    "### RBF SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da6e247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "svr = SVR()\n",
    "# Fit\n",
    "svr.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         svr, \"svm_rbf\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])\n",
    "all_results.sort_values(\"test_rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d42c4",
   "metadata": {},
   "source": [
    "### LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "48d9e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/miniforge3/envs/skywalker/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>2.044915</td>\n",
       "      <td>1.732313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network</td>\n",
       "      <td>2.043704</td>\n",
       "      <td>1.813406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64</td>\n",
       "      <td>2.065874</td>\n",
       "      <td>1.828010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64_init</td>\n",
       "      <td>2.096282</td>\n",
       "      <td>1.831205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_128</td>\n",
       "      <td>2.058027</td>\n",
       "      <td>1.868867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.969422</td>\n",
       "      <td>1.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>1.969422</td>\n",
       "      <td>1.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.969422</td>\n",
       "      <td>1.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64</td>\n",
       "      <td>2.011368</td>\n",
       "      <td>1.888757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-32_64</td>\n",
       "      <td>2.021202</td>\n",
       "      <td>1.914971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-128_128</td>\n",
       "      <td>2.032535</td>\n",
       "      <td>1.917668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear-2</td>\n",
       "      <td>2.035527</td>\n",
       "      <td>2.011698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-32_32</td>\n",
       "      <td>2.019506</td>\n",
       "      <td>2.041065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-32_32</td>\n",
       "      <td>1.998198</td>\n",
       "      <td>2.048241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear-3</td>\n",
       "      <td>2.071000</td>\n",
       "      <td>2.087890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>2.100350</td>\n",
       "      <td>2.094910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear-0.499</td>\n",
       "      <td>2.055698</td>\n",
       "      <td>2.122023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>2.076212</td>\n",
       "      <td>2.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear-1</td>\n",
       "      <td>2.047677</td>\n",
       "      <td>2.125393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>2.049621</td>\n",
       "      <td>2.130778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear-1-iter</td>\n",
       "      <td>2.049522</td>\n",
       "      <td>2.137109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear-1</td>\n",
       "      <td>2.049650</td>\n",
       "      <td>2.137711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64_init_bn</td>\n",
       "      <td>1.555074</td>\n",
       "      <td>2.178951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  train_rmse  test_rmse\n",
       "0                       svm_rbf    2.044915   1.732313\n",
       "0                neural_network    2.043704   1.813406\n",
       "0          neural_network-64_64    2.065874   1.828010\n",
       "0     neural_network-64_64_init    2.096282   1.831205\n",
       "0         neural_network-64_128    2.058027   1.868867\n",
       "0                        linear    1.969422   1.888512\n",
       "0                       svm_rbf    1.969422   1.888512\n",
       "0                        linear    1.969422   1.888512\n",
       "0          neural_network-64_64    2.011368   1.888757\n",
       "0          neural_network-32_64    2.021202   1.914971\n",
       "0        neural_network-128_128    2.032535   1.917668\n",
       "0                  svm_linear-2    2.035527   2.011698\n",
       "0          neural_network-32_32    2.019506   2.041065\n",
       "0          neural_network-32_32    1.998198   2.048241\n",
       "0                  svm_linear-3    2.071000   2.087890\n",
       "0                    svm_linear    2.100350   2.094910\n",
       "0              svm_linear-0.499    2.055698   2.122023\n",
       "0                    svm_linear    2.076212   2.124000\n",
       "0                  svm_linear-1    2.047677   2.125393\n",
       "0                    svm_linear    2.049621   2.130778\n",
       "0             svm_linear-1-iter    2.049522   2.137109\n",
       "0                  svm_linear-1    2.049650   2.137711\n",
       "0  neural_network-64_64_init_bn    1.555074   2.178951"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "epsilon = 0.499\n",
    "svr = LinearSVR(epsilon = epsilon)\n",
    "# Fit\n",
    "svr.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         svr, f\"svm_linear-{epsilon}\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])\n",
    "all_results.sort_values(\"test_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be38ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
