{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3256c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "# Descriptive statistics\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "## Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "## SVR\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "## Neural networks\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "## LGBM\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of annoying LGBM messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"categorical_column in param dict is overridden.\")\n",
    "warnings.filterwarnings(\"ignore\", message='Overriding the parameters from Reference Dataset.')\n",
    "warnings.filterwarnings(\"ignore\", message='The reported value is ignored because this*')\n",
    "warnings.filterwarnings(\"ignore\", message='Found `n_estimators` in params. Will use it*')\n",
    "warnings.filterwarnings(\"ignore\", message='The distribution is specified by*')\n",
    "\n",
    "# Hide optuna logging too\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543924db",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files to read in\n",
    "gcse_files = glob.glob(\"../fake_data/synthetic_*_gcse_20[1-2][0, 8-9].csv\")\n",
    "npd_files = glob.glob(\"../fake_data/synthetic_npd_ks4_student_20[1-2][0, 8-9].csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcd54b",
   "metadata": {},
   "source": [
    "## Exam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_grades(data = pd.DataFrame, grade_col = str):\n",
    "    \n",
    "    # Drop rows with missing grades\n",
    "    data = data.dropna(subset = grade_col)\n",
    "    # Convert U grade to 0\n",
    "    data.loc[data[grade_col] == \"U\", grade_col] = \"0\"\n",
    "    # Convert grades to numeric from string format\n",
    "    data = data[data[grade_col].isin([str(x) for x in (range(0, 10))])]\n",
    "    data[grade_col] = data[grade_col].astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b48f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gcse_data(df = pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes raw GCSE exam data (2017-2020 files), filters it\n",
    "    appropriately and processes it. \n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of raw GCSE data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy to prevent in-place changes\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Make cols lowercase\n",
    "    data.columns = [x.lower() for x in data.columns]\n",
    "    \n",
    "    # Reformat examseries to year col\n",
    "    data[\"year\"] = data.examseries.apply(lambda x: x.split()[1])\n",
    "    \n",
    "    # Remove candidates who were not 16 on 31st August\n",
    "    data = data.query(\"yearendage == 16\")\n",
    "    # Remove private candidates\n",
    "    data = data.query(\"privatecandidate == False\")\n",
    "    # Commented out below since all True in synthetic data\n",
    "    # Remove partial absentees\n",
    "#     data = data.query(\"partialabsence == False\")\n",
    "    # Remove candidates without prior attainment or that weren't matched in NPD\n",
    "    data = data.dropna(subset = [\"normalisedks2score\", \"npdmatchround\"])\n",
    "    \n",
    "    # Remove candidates with 0 prior attainment (errors in data)\n",
    "    data = data[data.normalisedks2score > 0]\n",
    "    \n",
    "    # Remove non-reformed GCSEs\n",
    "    data = data[data.reformphase.isin(['Ofqual-regulated Phase 1 reformed GCSE FC',\n",
    "                                       'Ofqual-regulated Phase 2 reformed GCSE FC'])]\n",
    "    # Recode tier into foundation or not foundation\n",
    "    data.loc[data.tier != \"F\", \"tier\"] = \"Not F\"\n",
    "    \n",
    "    # Process grade column inplace\n",
    "    data = process_grades(data, grade_col = \"grade\")\n",
    "    \n",
    "    # Standardise the KS2 prior attainment to between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    data.normalisedks2score = scaler.fit_transform(data[['normalisedks2score']])\n",
    "    \n",
    "    # Get candidates who took at least 8 GCSEs\n",
    "    grouped = data.groupby(\"uidp\").count()\n",
    "    at_least_8 = set(grouped[grouped.examseries >= 8].index.to_list())\n",
    "    # Get candidates who took English and Maths\n",
    "    eng_math = set(data[data.jcqtitle.isin([\"Mathematics\", \"English language\"])].uidp)\n",
    "    # Get candidates who took English and Maths and >= 8 GCSEs\n",
    "    filtered_ids = at_least_8 & eng_math\n",
    "    # Beware that since this is simulated data, it's wrong\n",
    "    filtered = data[data.uidp.isin(filtered_ids)]\n",
    "    \n",
    "    # Select cols needed for modelling and dropnas\n",
    "    gcse_cols = [\"uidp\", \"year\", \"jcqtitle\", \"tier\", \"centretypedesc\",\n",
    "                 \"normalisedks2score\", \"grade\", \"centreassessmentgrade\"]\n",
    "    filtered = filtered[gcse_cols]\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d381e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process all the GCSE exam data\n",
    "gcse_data = pd.DataFrame()\n",
    "# Iterate through files\n",
    "for file in gcse_files:\n",
    "    # Perform filtering/pre-processing\n",
    "    year_df = process_gcse_data(pd.read_csv(file))\n",
    "    # Process the CAG column too\n",
    "    if \"2020\" in file:\n",
    "        year_df = process_grades(year_df, \"centreassessmentgrade\")\n",
    "    # Create dummy value for other years\n",
    "    else:\n",
    "        year_df.centreassessmentgrade = np.NaN\n",
    "        \n",
    "    # Merge with other years\n",
    "    gcse_data = pd.concat([gcse_data, year_df])\n",
    "    # Delete var to save memory\n",
    "    del year_df\n",
    "# Reset index\n",
    "gcse_data = gcse_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a smaller sample of the GCSE data, overwrite the orignal gcse_data object too\n",
    "gcse_data, unneeded_gcse_data = train_test_split(gcse_data, \n",
    "                                                  train_size = 0.1, \n",
    "                                                  stratify = gcse_data.year,\n",
    "                                                  random_state = 42, shuffle = True)\n",
    "del unneeded_gcse_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3c64c",
   "metadata": {},
   "source": [
    "## NPD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_npd(data = pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes raw NPD data (2017-2020 files), filters it\n",
    "    appropriately and processes it. \n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of raw NPD data\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Copy to prevent inplace changes\n",
    "    df = data.copy()\n",
    "    # Make cols lowercase\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    # Select the columns that are common across files\n",
    "    npd_cols = [\"uidp\", \"ks4_ealgrp_ptq_ee\", \"ks4_gender\"]\n",
    "    # Get the bases for the columns that change in suffix in each file\n",
    "    col_bases = [\"ethnicgroupmajor\", \"fsmeligible\", \"senprovisionmajor\"]\n",
    "    # Get the suffix part that changes\n",
    "    year_ending = int(file[-6:-4])\n",
    "    # Dynamically select those cols with changing suffixes\n",
    "    npd_cols.extend([col_base + f\"_spr{year_ending}\" for col_base in col_bases])\n",
    "    # Also add in most recent IDACI score\n",
    "    npd_cols.append(sorted([x for x in df.columns if \"idaciscore\" in x])[-1])\n",
    "    \n",
    "    # Select the needed columns\n",
    "    df = df[npd_cols]\n",
    "    # Add in year col\n",
    "    df[\"year\"] = f\"20{year_ending}\"\n",
    "    # Rename columns\n",
    "    clean_cols = [\"uidp\", \"eal\", \"gender\", \"ethnicity\",\n",
    "              \"fsm\", \"sen\", \"idaci\", \"year\"]\n",
    "    df.columns = clean_cols\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9927c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy code for checking cols are consistent\n",
    "# col_dict = dict()\n",
    "# for file in npd_files:\n",
    "#     col_dict[file[-8:-4]] = pd.read_csv(file).columns\n",
    "# set(col_dict[\"2020\"]) & set(col_dict[\"2019\"]) & set(col_dict[\"2018\"])\n",
    "# set(col_dict[\"2020\"]) - set(col_dict[\"2019\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143102ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df to store each year's data in\n",
    "npd_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through files\n",
    "for file in npd_files:\n",
    "    # Load data\n",
    "    npd_df = pd.read_csv(file)\n",
    "    # Process the NPD data\n",
    "    npd_df = process_npd(npd_df)\n",
    "    # Combine into dataframe\n",
    "    npd_data = pd.concat([npd_data, npd_df])\n",
    "    \n",
    "    # Delete var to save memory\n",
    "    del npd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c918d",
   "metadata": {},
   "source": [
    "# Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ba32f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def recode_cols(data = pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Takes processed merged GCSE exam and NPD data (2017-2020 files),\n",
    "    filters it appropriately and processes it. \n",
    "    It recodes several columns into fewer numbers of categories\n",
    "    to make modelling easier.\n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of merged NPD/GCSE data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy to prevent inplace changes\n",
    "    df = data.copy()\n",
    "    # Filter EAL to remove NAs or unclassifieds\n",
    "    df = df[df.eal.isin([1,2])]\n",
    "    # Filter ethnicity to remove unclassifieds/NaNs\n",
    "    df = df[df.ethnicity.isin([\"AOEG\", \"ASIA\", \"BLAC\", \"CHIN\",\n",
    "                          \"MIXD\", \"WHIT\"])]\n",
    "    # Filter and recode SEN to remove unclassifieds and make SEN/not SEN\n",
    "    df = df[df.sen.isin([\"1_NON\", \"2_SNS\", \"3_SS\"])]\n",
    "    df.loc[df.sen != \"1_NON\", \"sen\"] = \"SEN\"\n",
    "    df.loc[df.sen == \"1_NON\", \"sen\"] = \"No SEN\"\n",
    "    \n",
    "    # Drop remaining NaNs from FSM and IDACI cols\n",
    "    df = df.dropna(subset = [\"fsm\", \"idaci\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join exam data with NPD data\n",
    "merged = npd_data.merge(gcse_data, on = [\"uidp\", \"year\"],\n",
    "                       how = \"inner\")\n",
    "\n",
    "# Recode columns and filter further\n",
    "df = recode_cols(merged)\n",
    "\n",
    "# Recode columns and filter further\n",
    "df = recode_cols(merged)\n",
    "\n",
    "# Get list of most common subjects to plot with later\n",
    "most_common_subjects = df.groupby(\"jcqtitle\").count()\\\n",
    ".sort_values(\"eal\", ascending = False)\\\n",
    ".head(10)\\\n",
    ".index\\\n",
    ".to_list()\n",
    "\n",
    "# Drop now unnecesary UIDP and year cols\n",
    "df = df.drop(columns = [\"year\", \"uidp\"])\n",
    "\n",
    "# Convert categorical cols to numerics\n",
    "categorical_cols = [\"eal\", \"gender\", \"ethnicity\", \"fsm\",\n",
    "               \"sen\", \"jcqtitle\", \"tier\", \"centretypedesc\"]\n",
    "\n",
    "# Encode categorical columns as numerics\n",
    "# Create mapping to inverse transform with later\n",
    "mapping = {}\n",
    "# Iterate through categorical columns\n",
    "for col in categorical_cols:\n",
    "    # Instantiate encoder\n",
    "    encoder = OrdinalEncoder()\n",
    "    # Store encoding in mapping dict\n",
    "    mapping[col] = encoder.fit(df[col].values.reshape(-1, 1))\n",
    "    # Convert column to numerics\n",
    "    df[col] = encoder.transform(df[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into treatment and control\n",
    "treatment = df[~df.centreassessmentgrade.isna()].copy()\n",
    "control = df[df.centreassessmentgrade.isna()].copy()\n",
    "\n",
    "# Split into labels and features\n",
    "X = np.array(control.iloc[:, :10], dtype = \"float32\")\n",
    "y = np.array(control.grade, dtype = \"float32\")\n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                   shuffle = True,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cbf133",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84173beb",
   "metadata": {},
   "source": [
    "## Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary stats of continuous variables\n",
    "continuous_cols = ['idaci', 'normalisedks2score', 'grade', 'centreassessmentgrade']\n",
    "control_continuous = control[continuous_cols].apply([np.mean, np.std]).T\n",
    "treatment_continuous = treatment[continuous_cols].apply([np.mean, np.std]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a101719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary stats\n",
    "summary_cont = pd.merge(control_continuous,\n",
    "                        treatment_continuous,\n",
    "                        how = \"inner\",\n",
    "                        left_index = True,\n",
    "                        right_index = True,\n",
    "                        suffixes = [\"_control\", \"_treatment\"])\n",
    "# Run t-tests\n",
    "summary_cont[\"p_val\"] = np.NaN\n",
    "for col in continuous_cols:\n",
    "    # Run t-test over each continuous col\n",
    "    t_test = ttest_ind(treatment[col], control[col])\n",
    "    # Store p-value\n",
    "    summary_cont.loc[col, \"p_val\"] = t_test.pvalue\n",
    "    \n",
    "# Export results\n",
    "summary_cont.to_csv(\"descriptive-continuous.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143e1ea",
   "metadata": {},
   "source": [
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd37c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert categorical cols back into original label form\n",
    "for col in categorical_cols:\n",
    "    # Inverse transform columns\n",
    "    control[col] = mapping[col].inverse_transform(control[col].values.reshape(-1, 1))\n",
    "    treatment[col] = mapping[col].inverse_transform(treatment[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportions in each group\n",
    "summary_cat = pd.DataFrame()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # Get frequencies and proportions for categories in group\n",
    "    # For control\n",
    "    control_count = control.groupby(col)[\"eal\"].count()\n",
    "    control_prop =  control_count / control.shape[0]\n",
    "    control_sum = pd.DataFrame(data = {\"control_count\":control_count,\n",
    "                                       \"control_prop\": control_prop,\n",
    "                                       \"col\": col})\n",
    "    # For treatment\n",
    "    treatment_count = treatment.groupby(col)[\"eal\"].count()\n",
    "    treatment_prop = treatment_count / treatment.shape[0]\n",
    "    treatment_sum = pd.DataFrame(data = {\"treatment_count\":treatment_count,\n",
    "                                         \"treatment_prop\": treatment_prop,\n",
    "                                         \"col\": col})\n",
    "    # Combine into one df\n",
    "    comparison = pd.concat([control_sum,\n",
    "                            treatment_sum[[\"treatment_count\", \"treatment_prop\"]]], axis = 1).fillna(0)\n",
    "    # Run chi-square test\n",
    "    chi2, p, dof, exp = chi2_contingency(comparison[[\"control_count\", \"treatment_count\"]])\n",
    "    # Add p-values to df\n",
    "    comparison[\"p_val\"] = p\n",
    "    \n",
    "    # Merge with other results\n",
    "    summary_cat = pd.concat([summary_cat, comparison])\n",
    "\n",
    "# Rename index\n",
    "summary_cat.index.name = \"category\"\n",
    "summary_cat = summary_cat.reset_index()\n",
    "# Export results\n",
    "summary_cat.to_csv(\"descriptive-categoricals.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24946572",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a9912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot most common subject mean grades, treatment vs control\n",
    "subject_treat = treatment.groupby(\"jcqtitle\")[[\"grade\"]].mean()\\\n",
    ".loc[most_common_subjects].reset_index().round(2)\n",
    "subject_control = control.groupby(\"jcqtitle\")[[\"grade\"]].mean()\\\n",
    ".loc[most_common_subjects].reset_index().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot treatment\n",
    "fig = sns.barplot(x = \"jcqtitle\", y = \"grade\", data = subject_treat)\n",
    "fig.tick_params(axis='x', rotation=60)\n",
    "fig.set(xlabel = \"Subject\", ylabel = \"Mean Grade\",\n",
    "        title = \"Mean Grades | Most Common 10 Subjects| Treatment\")\n",
    "fig.bar_label(fig.containers[0]);\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"treatment_subj_grades.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot control\n",
    "fig = sns.barplot(x = \"jcqtitle\", y = \"grade\", data = subject_control)\n",
    "fig.tick_params(axis='x', rotation=60)\n",
    "fig.set(xlabel = \"Subject\", ylabel = \"Mean Grade\",\n",
    "        title = \"Mean Grades | Most Common 10 Subjects| Control\")\n",
    "fig.bar_label(fig.containers[0]);\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"control_subj_grades.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145f260",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9449e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe to store model results in\n",
    "all_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e4087",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, X_test,\n",
    "                  y_train, y_test,\n",
    "                  model, model_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to evaluate a model in terms of\n",
    "    train and test RMSE.\n",
    "    Returns a dataframe of model name and RMSEs.\n",
    "    --------------------------------------------------\n",
    "    X_train = np.array of X data, used to generate train RMSE\n",
    "    X_test = np.array of X data, used to generate test RMSE\n",
    "    y_train = np.array of y data, used to generate train RMSE\n",
    "    y_test = np.array of y data, used to generate test RMSE\n",
    "    model = fitted model instance to use with model.predict\n",
    "    model_name = str, name to save the model under\n",
    "    \"\"\"\n",
    "    # Generate predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    # Evaluate model\n",
    "    train_rmse = mean_squared_error(y_train, train_preds, squared = False)\n",
    "    test_rmse = mean_squared_error(y_test, test_preds, squared = False)\n",
    "\n",
    "    # Store results\n",
    "    results = pd.DataFrame({\"model\": model_name,\n",
    "                            \"train_rmse\": train_rmse,\n",
    "                            \"test_rmse\": test_rmse,\n",
    "                 }, index = [0])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0a8ea",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5abc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create linear model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         linear_model, \"ols_linear\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22357ac1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf2ae9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The 32-32 network seemed to work quite well. Could also try it with batch normalisation, same again with 64-64 networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cb932",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(X_data,\n",
    "              layer_1_units = 64,\n",
    "              layer_2_units = 64,\n",
    "              batch_normalization = False,\n",
    "              loss = \"mse\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"mse\"]):\n",
    "    \"\"\"\n",
    "    Function to create artificial neural network. Dense layer\n",
    "    units can be specified, as can the use of batch normalization\n",
    "    in between the dense layers (this provides mild regularisation)\n",
    "    and may speed up training.\n",
    "    Returns a compiled Keras model.\n",
    "    --------------------------------------------------\n",
    "    X_data = np.array of X data, used to give input shape to model\n",
    "    layer_1_units = int, number of neurons in 1st hidden layer\n",
    "    layer_2_units = int, number of neurons in 2nd hidden layer\n",
    "    batch_normalization = bool, batch normalize between hidden layers \n",
    "    if true\n",
    "    loss = str, name of loss function to use\n",
    "    optimizer = str or keras.Optimzer object, optimizer to use\n",
    "    metrics = list of strings, evaluation metrics to use\n",
    "    \"\"\"\n",
    "    # Build model\n",
    "    model = Sequential(name = \"MLP\")\n",
    "    # 1st Dense layer\n",
    "    model.add(Dense(units = layer_1_units, activation = \"relu\", input_shape = (X_data.shape[1], ),\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    \n",
    "    # Add batch normalization if desired\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    # 2nd Dense layer\n",
    "    model.add(Dense(units = layer_2_units, activation = \"relu\",\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    # Output layer\n",
    "    model.add(Dense(units = 1, activation = \"linear\",\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    # Compile model\n",
    "    model.compile(**compile_hp)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88baf23e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hyperparams used during modelling\n",
    "# Compilation hyperparams\n",
    "compile_hp = dict()\n",
    "compile_hp[\"loss\"] = \"mse\"\n",
    "compile_hp[\"optimizer\"] = optimizers.Adam(learning_rate = 0.001)\n",
    "compile_hp[\"metrics\"] = [\"mse\"]\n",
    "\n",
    "# Fitting hyperparams\n",
    "fit_hp = dict()\n",
    "fit_hp[\"batch_size\"] = 32\n",
    "fit_hp[\"epochs\"] = 200\n",
    "fit_hp[\"validation_split\"] = 0.2\n",
    "# Create callback to select the best model\n",
    "fit_hp[\"callbacks\"] = EarlyStopping(monitor = \"val_loss\",\n",
    "                                         mode = \"min\",\n",
    "                                         restore_best_weights = True,\n",
    "                                         patience = 25)\n",
    "\n",
    "# Eliminate verbose to have a neater notebook \n",
    "fit_hp[\"verbose\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abe51f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14561def",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 32\n",
    "layer_2_units = 32\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = True\n",
    "\n",
    "# Build and compile model\n",
    "mlp = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = mlp.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Get string to save model details with\n",
    "save_name  = f\"neural_network-{layer_1_units}_{layer_2_units}\"\n",
    "if batch_normalization:\n",
    "    save_name = save_name + \"_bn\"\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         mlp, save_name)\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02747447",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c728573",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Params to compile LGBM model with\n",
    "fixed_params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': \"rmse\",  \n",
    "        'verbosity': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2812b5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    \"\"\"\n",
    "    Wrapper function to work with Optuna trial objects, \n",
    "    enabling Hyperband hyperparameter search.\n",
    "    \"\"\"   \n",
    "    # Suggest hyperparams to test using Optuna trial object.\n",
    "    param = {**fixed_params,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 3000, step = 20),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.2, 0.99, step = 0.05),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.2, 0.99, step = 0.05),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 5000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 2000, step=5),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 10),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "    }\n",
    "    \n",
    "    # Create cv object\n",
    "    cv = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "    # Make empty array to store cv RMSE scores in\n",
    "    cv_scores = np.empty(5)\n",
    "    \n",
    "    # Split into K train and validation sets and iterate through them\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        # Split into training and validation CV sets\n",
    "        X_train_cv, X_test_cv = X[train_idx], X[test_idx]\n",
    "        y_train_cv, y_test_cv = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Convert data to proper LGBM format\n",
    "        train_data = lgb.Dataset(X_train_cv, label = y_train_cv,\n",
    "                                 categorical_feature = [0,1,2,3,4,6,7,8])\n",
    "        val_data = lgb.Dataset(X_test_cv, label = y_test_cv, \n",
    "                               categorical_feature = [0,1,2,3,4,6,7,8],\n",
    "                              reference = train_data)\n",
    "        \n",
    "        # Make callbacks to prevent trialling hyperparams that are obviously bad\n",
    "        callbacks = [\n",
    "            LightGBMPruningCallback(trial, metric = \"rmse\"),\n",
    "                     # Callback to reduce model validation performance messages\n",
    "                    lgb.log_evaluation(period = 100),\n",
    "                     # Early stoppping to prevent overfitting training data\n",
    "                    lgb.early_stopping(100)]\n",
    "\n",
    "        # Training the model\n",
    "        model = lgb.train(params = param,  train_set = train_data,\n",
    "                          valid_sets = val_data,   \n",
    "                          callbacks = callbacks,\n",
    "                         )\n",
    "    \n",
    "        # Get predictions\n",
    "        preds = model.predict(X_test_cv)\n",
    "        # Calculate RMSE\n",
    "        cv_scores[idx] = mean_squared_error(y_test_cv, preds, squared = False)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86154180",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture my_study\n",
    "# Above line magic hides lengthy output, but stores into first_round if you want to look\n",
    "\n",
    "# Create Optuna study to do CV hyperparameter search\n",
    "study = optuna.create_study(direction = \"minimize\", # minimizing RMSE\n",
    "                            study_name = \"LGBM Classifier\",\n",
    "                           pruner = optuna.pruners.HyperbandPruner())\n",
    "func = lambda trial: objective(trial, X = X_train, y = y_train)\n",
    "study.optimize(func, n_trials = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387684e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run best model and evaluate\n",
    "# Convert data to proper LGBM format\n",
    "train_data = lgb.Dataset(X_train, label = y_train,\n",
    "                         categorical_feature = [0,1,2,3,4,6,7,8])\n",
    "\n",
    "# Callback to reduce model messages\n",
    "callbacks = [lgb.log_evaluation(period = 100)]\n",
    "\n",
    "# Training the model using the best params identified in study\n",
    "lgbm = lgb.train(params = {**fixed_params, **study.best_params},\n",
    "                  train_set = train_data, \n",
    "                  callbacks = callbacks,\n",
    "                 )\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         lgbm, \"lgbm\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da8826",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bccd0b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### RBF SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a816e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "rbf_svr = SVR()\n",
    "# Fit\n",
    "rbf_svr.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         rbf_svr, \"svm_rbf\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3362182f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ae93e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "epsilon = 0.499\n",
    "linear_svr = LinearSVR(epsilon = epsilon)\n",
    "# Fit\n",
    "linear_svr.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         linear_svr, f\"svm_linear-{epsilon}\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e57ab",
   "metadata": {},
   "source": [
    "# Analysing Results / Using Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646dc686",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performances\n",
    "best = all_results.sort_values(\"test_rmse\").head(1)\n",
    "all_results.sort_values(\"test_rmse\")\n",
    "all_results.to_csv(\"model_evaluations.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model and it's test RMSE\n",
    "best_model = lgbm\n",
    "best_rmse = best.test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94cc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get treatment in numeric form again\n",
    "treatment = df[~df.centreassessmentgrade.isna()].copy()\n",
    "\n",
    "# Split into labels and features\n",
    "X_treatment = np.array(treatment.iloc[:, :10], dtype = \"float32\")\n",
    "y_treatment = np.array(treatment.grade, dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions for 2020 year using best model\n",
    "treatment[\"predictions\"] = best_model.predict(X_treatment)\n",
    "# Calculate differences from CAG\n",
    "treatment[\"cag_diff\"] = treatment.centreassessmentgrade - treatment.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quantiles for IDACI and prior attainment\n",
    "quantile_labels = [\"very low\", \"low\", \"medium\", \"high\", \"very high\"]\n",
    "treatment[\"idaci_quantile\"] = pd.qcut(treatment.idaci, \n",
    "                                      q = 5,\n",
    "                                      labels = quantile_labels)\n",
    "treatment[\"attainment_quantile\"] = pd.qcut(treatment.normalisedks2score, \n",
    "                                      q = 5,\n",
    "                                      labels = quantile_labels)\n",
    "# Reconvert categorical cols back into original label form\n",
    "for col in categorical_cols:\n",
    "    # Inverse transform columns\n",
    "    treatment[col] = mapping[col].inverse_transform(treatment[col].values.reshape(-1, 1))\n",
    "    \n",
    "# Create neater labels for certain columns\n",
    "# EAL\n",
    "eal_mappings = {1.0:\"No EAL\", 2.0: \"EAL\"}\n",
    "treatment.eal = treatment.eal.replace(eal_mappings)\n",
    "# FSM\n",
    "fsm_mappings = {0:\"No FSM\", 1: \"FSM\"}\n",
    "treatment.fsm = treatment.fsm.replace(fsm_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8c760",
   "metadata": {},
   "source": [
    "## Analyse Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of factors to aggregate by, including intersectional factors\n",
    "groupers = [[\"ethnicity\", \"idaci_quantile\"],\n",
    "            [\"ethnicity\", \"attainment_quantile\"],\n",
    "            [\"ethnicity\", \"idaci_quantile\", \"attainment_quantile\"],\n",
    "            [\"ethnicity\", \"idaci_quantile\", \"attainment_quantile\", \"eal\"],\n",
    "            [\"ethnicity\", \"idaci_quantile\", \"attainment_quantile\", \"fsm\"],\n",
    "            [\"ethnicity\", \"idaci_quantile\", \"attainment_quantile\", \"sen\"],\n",
    "            [\"ethnicity\", \"idaci_quantile\", \"attainment_quantile\", \"tier\"],\n",
    "            [\"idaci_quantile\", \"attainment_quantile\"],\n",
    "            [\"idaci_quantile\", \"fsm\"],\n",
    "            [\"idaci_quantile\", \"fsm\", \"attainment_quantile\"],\n",
    "            [\"sen\", \"ethnicity\"],\n",
    "            [\"sen\", \"idaci_quantile\"],\n",
    "            [\"sen\", \"attainment_quantile\"],\n",
    "            [\"eal\", \"ethnicity\"],\n",
    "            [\"eal\", \"idaci_quantile\"],\n",
    "            [\"eal\", \"attainment_quantile\"],\n",
    "            'eal', 'gender', 'ethnicity',\n",
    "            'fsm', 'sen', 'jcqtitle', 'tier',\n",
    "            'centretypedesc','idaci_quantile',\n",
    "            'attainment_quantile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df to store each group's results in\n",
    "all_groups = pd.DataFrame()\n",
    "for grouper in groupers:\n",
    "    group_df = treatment.groupby(grouper)[\"cag_diff\"].mean().reset_index()\n",
    "    # Store values for factor and factor values\n",
    "    group_df[\"factor\"] = \"X\".join(grouper) if isinstance(grouper, list) else grouper\n",
    "    group_df[\"factor_value\"] = group_df.iloc[:, 0].astype(str)\n",
    "    \n",
    "    # Also concat factor value when grouper is more than 1 item\n",
    "    if isinstance(grouper, list):\n",
    "        for i in range(1, len(grouper)):\n",
    "            group_df[\"factor_value\"] = group_df[\"factor_value\"] + \" X \" + group_df.iloc[:, i].astype(str)\n",
    "    \n",
    "    # Save results to df\n",
    "    all_groups = pd.concat([all_groups, group_df[[\"factor\", \"factor_value\", \"cag_diff\"]]])\n",
    "\n",
    "# Export results\n",
    "all_groups.sort_values([\"factor\", \"factor_value\"]).to_csv(\"predicted_diffs.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
