{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfa8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2e54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric\n",
    "# rmse = mean_squared_error(y_actual, y_predicted, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5b505",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed5a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files to read in\n",
    "gcse_files = glob.glob(\"../fake_data/synthetic_*_gcse_20[1-2][0, 8-9].csv\")\n",
    "npd_files = glob.glob(\"../fake_data/synthetic_npd_ks4_student_20[1-2][0, 8-9].csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277b497",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7a0875",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_grades(data = pd.DataFrame, grade_col = str):\n",
    "    \n",
    "    # Drop rows with missing grades\n",
    "    data = data.dropna(subset = grade_col)\n",
    "    # Convert U grade to 0\n",
    "    data.loc[data[grade_col] == \"U\", grade_col] = \"0\"\n",
    "    # Convert grades to numeric from string format\n",
    "    data = data[data[grade_col].isin([str(x) for x in (range(0, 10))])]\n",
    "    data[grade_col] = data[grade_col].astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa77d8f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_gcse_data(df = pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes raw GCSE exam data (2017-2020 files), filters it\n",
    "    appropriately and processes it. \n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of raw GCSE data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy to prevent in-place changes\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Make cols lowercase\n",
    "    data.columns = [x.lower() for x in data.columns]\n",
    "    \n",
    "    # Reformat examseries to year col\n",
    "    data[\"year\"] = data.examseries.apply(lambda x: x.split()[1])\n",
    "    \n",
    "    # Remove candidates who were not 16 on 31st August\n",
    "    data = data.query(\"yearendage == 16\")\n",
    "    # Remove private candidates\n",
    "    data = data.query(\"privatecandidate == False\")\n",
    "    # Commented out below since all True in synthetic data\n",
    "    # Remove partial absentees\n",
    "#     data = data.query(\"partialabsence == False\")\n",
    "    # Remove candidates without prior attainment or that weren't matched in NPD\n",
    "    data = data.dropna(subset = [\"normalisedks2score\", \"npdmatchround\"])\n",
    "    \n",
    "    # Remove candidates with 0 prior attainment (errors in data)\n",
    "    data = data[data.normalisedks2score > 0]\n",
    "    \n",
    "    # Remove non-reformed GCSEs\n",
    "    data = data[data.reformphase.isin(['Ofqual-regulated Phase 1 reformed GCSE FC',\n",
    "                                       'Ofqual-regulated Phase 2 reformed GCSE FC'])]\n",
    "    # Recode tier into foundation or not foundation\n",
    "    data.loc[data.tier != \"F\", \"tier\"] = \"Not F\"\n",
    "    \n",
    "    # Process grade column inplace\n",
    "    data = process_grades(data, grade_col = \"grade\")\n",
    "    \n",
    "    # Standardise the KS2 prior attainment to between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    data.normalisedks2score = scaler.fit_transform(data[['normalisedks2score']])\n",
    "    \n",
    "    # Get candidates who took at least 8 GCSEs\n",
    "    grouped = data.groupby(\"uidp\").count()\n",
    "    at_least_8 = set(grouped[grouped.examseries >= 8].index.to_list())\n",
    "    # Get candidates who took English and Maths\n",
    "    eng_math = set(data[data.jcqtitle.isin([\"Mathematics\", \"English language\"])].uidp)\n",
    "    # Get candidates who took English and Maths and >= 8 GCSEs\n",
    "    filtered_ids = at_least_8 & eng_math\n",
    "    # Beware that since this is simulated data, it's wrong\n",
    "    filtered = data[data.uidp.isin(filtered_ids)]\n",
    "    \n",
    "    # Select cols needed for modelling and dropnas\n",
    "    gcse_cols = [\"uidp\", \"year\", \"jcqtitle\", \"tier\", \"centretypedesc\",\n",
    "                 \"normalisedks2score\", \"grade\", \"centreassessmentgrade\"]\n",
    "    filtered = filtered[gcse_cols]\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8da802",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load and process all the GCSE exam data\n",
    "gcse_data = pd.DataFrame()\n",
    "# Iterate through files\n",
    "for file in gcse_files:\n",
    "    # Perform filtering/pre-processing\n",
    "    year_df = process_gcse_data(pd.read_csv(file))\n",
    "    # Process the CAG column too\n",
    "    if \"2020\" in file:\n",
    "        year_df = process_grades(year_df, \"centreassessmentgrade\")\n",
    "    # Create dummy value for other years\n",
    "    else:\n",
    "        year_df.centreassessmentgrade = np.NaN\n",
    "        \n",
    "    # Merge with other years\n",
    "    gcse_data = pd.concat([gcse_data, year_df])\n",
    "    # Delete var to save memory\n",
    "    del year_df\n",
    "# Reset index\n",
    "gcse_data = gcse_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff4d92",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NPD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9a8002",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_npd(data = pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes raw NPD data (2017-2020 files), filters it\n",
    "    appropriately and processes it. \n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of raw NPD data\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Copy to prevent inplace changes\n",
    "    df = data.copy()\n",
    "    # Make cols lowercase\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    # Select the columns that are common across files\n",
    "    npd_cols = [\"uidp\", \"ks4_ealgrp_ptq_ee\", \"ks4_gender\"]\n",
    "    # Get the bases for the columns that change in suffix in each file\n",
    "    col_bases = [\"ethnicgroupmajor\", \"fsmeligible\", \"senprovisionmajor\"]\n",
    "    # Get the suffix part that changes\n",
    "    year_ending = int(file[-6:-4])\n",
    "    # Dynamically select those cols with changing suffixes\n",
    "    npd_cols.extend([col_base + f\"_spr{year_ending}\" for col_base in col_bases])\n",
    "    # Also add in most recent IDACI score\n",
    "    npd_cols.append(sorted([x for x in df.columns if \"idaciscore\" in x])[-1])\n",
    "    \n",
    "    # Select the needed columns\n",
    "    df = df[npd_cols]\n",
    "    # Add in year col\n",
    "    df[\"year\"] = f\"20{year_ending}\"\n",
    "    # Rename columns\n",
    "    clean_cols = [\"uidp\", \"eal\", \"gender\", \"ethnicity\",\n",
    "              \"fsm\", \"sen\", \"idaci\", \"year\"]\n",
    "    df.columns = clean_cols\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af573b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_dict = dict()\n",
    "for file in npd_files:\n",
    "    col_dict[file[-8:-4]] = pd.read_csv(file).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4847a18b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set(col_dict[\"2020\"]) & set(col_dict[\"2019\"]) & set(col_dict[\"2018\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb16fe32",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set(col_dict[\"2020\"]) - set(col_dict[\"2019\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01baa59a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create df to store each year's data in\n",
    "npd_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through files\n",
    "for file in npd_files:\n",
    "    # Load data\n",
    "    df = pd.read_csv(file)\n",
    "    # Process the NPD data\n",
    "    df = process_npd(df)\n",
    "    # Combine into dataframe\n",
    "    npd_data = pd.concat([npd_data, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4339b85",
   "metadata": {},
   "source": [
    "# Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40882a47",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def recode_cols(data = pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Takes processed merged GCSE exam and NPD data (2017-2020 files),\n",
    "    filters it appropriately and processes it. \n",
    "    It recodes several columns into fewer numbers of categories\n",
    "    to make modelling easier.\n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of merged NPD/GCSE data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy to prevent inplace changes\n",
    "    df = data.copy()\n",
    "    # Filter EAL to remove NAs or unclassifieds\n",
    "    df = df[df.eal.isin([1,2])]\n",
    "    # Filter ethnicity to remove unclassifieds/NaNs\n",
    "    df = df[df.ethnicity.isin([\"AOEG\", \"ASIA\", \"BLAC\", \"CHIN\",\n",
    "                          \"MIXD\", \"WHIT\"])]\n",
    "    # Filter and recode SEN to remove unclassifieds and make SEN/not SEN\n",
    "    df = df[df.sen.isin([\"1_NON\", \"2_SNS\", \"3_SS\"])]\n",
    "    df.loc[df.sen != \"1_NON\", \"sen\"] = \"SEN\"\n",
    "    df.loc[df.sen == \"1_NON\", \"sen\"] = \"No SEN\"\n",
    "    \n",
    "    # Drop remaining NaNs from FSM and IDACI cols\n",
    "    df = df.dropna(subset = [\"fsm\", \"idaci\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a771c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join exam data with NPD data\n",
    "merged = npd_data.merge(gcse_data, on = [\"uidp\", \"year\"],\n",
    "                       how = \"inner\")\n",
    "\n",
    "# Recode columns and filter further\n",
    "df = recode_cols(merged)\n",
    "\n",
    "# Drop now unnecesary UIDP and year cols\n",
    "df = df.drop(columns = [\"year\", \"uidp\"])\n",
    "\n",
    "# Convert categorical cols to numerics\n",
    "categorical_cols = [\"eal\", \"gender\", \"ethnicity\", \"fsm\",\n",
    "               \"sen\", \"jcqtitle\", \"tier\", \"centretypedesc\"]\n",
    "# Fit encoder on categorical cols\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(df[categorical_cols])\n",
    "\n",
    "# Create a mapping for reference later\n",
    "mapping = {k:v for k, v in zip(categorical_cols, encoder.categories_)}\n",
    "\n",
    "# Convert categoricals to numerics\n",
    "df[categorical_cols] = encoder.transform(df[categorical_cols])\n",
    "\n",
    "# Split into treatment and control\n",
    "treatment = df[~df.centreassessmentgrade.isna()]\n",
    "control = df[df.centreassessmentgrade.isna()]\n",
    "# Old code, maybe useful for LGBM\n",
    "# df[categorical_cols] = df[categorical_cols].apply(pd.Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19ceb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into labels and features\n",
    "X = np.array(control.iloc[:, :10], dtype = \"float32\")\n",
    "y = control.grade.astype(\"float32\")\n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                   shuffle = True,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ff4ff",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Quick EDA / Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f6b68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31678e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report = ProfileReport(df, title = \"eda_check\")\n",
    "report.to_file(\"eda_check.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb004d0",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store relevant results\n",
    "results = pd.DataFrame({\"pca_cutoff\": n_components,\n",
    "              \"train_error\": train_error,\n",
    "              \"cv_error\": cv_error,\n",
    "              \"test_error\": \"INSERT KAGGLE TEST ERROR HERE\",\n",
    "              \"notes\": \"keras\"\n",
    "             }, index = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e413a",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2f0301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Generate predictions\n",
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "# Evaluate model\n",
    "train_rmse = mean_squared_error(y_train, train_preds, squared = False)\n",
    "test_rmse = mean_squared_error(y_test, test_preds, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9b2237d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9694222"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4381676e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8885119"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f90790d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05491288326979671"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79b0effa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.306453 , 5.3161955, 5.6981063, 4.2989902, 3.59236  , 4.139867 ,\n",
       "       4.799478 , 4.791337 , 4.093174 , 3.6184897, 4.530363 , 3.7817087,\n",
       "       5.118941 , 5.438796 , 4.879112 , 5.411968 , 5.1208596, 3.093658 ,\n",
       "       4.7135053, 5.394718 , 5.293175 , 4.105444 , 4.178582 , 5.257522 ,\n",
       "       4.4387527, 4.7380795], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b389b6",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803074b",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e0924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
