{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3672b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "## Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "## SVR\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "## Neural networks\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "## LGBM\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f568af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of annoying LGBM messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"categorical_column in param dict is overridden.\")\n",
    "warnings.filterwarnings(\"ignore\", message='Overriding the parameters from Reference Dataset.')\n",
    "warnings.filterwarnings(\"ignore\", message='The reported value is ignored because this*')\n",
    "warnings.filterwarnings(\"ignore\", message='Found `n_estimators` in params. Will use it*')\n",
    "warnings.filterwarnings(\"ignore\", message='The distribution is specified by*')\n",
    "\n",
    "# Hide optuna logging too\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d92254",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c736d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files to read in\n",
    "gcse_files = glob.glob(\"../fake_data/synthetic_*_gcse_20[1-2][0, 8-9].csv\")\n",
    "npd_files = glob.glob(\"../fake_data/synthetic_npd_ks4_student_20[1-2][0, 8-9].csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74881e81",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ccc10d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_grades(data = pd.DataFrame, grade_col = str):\n",
    "    \n",
    "    # Drop rows with missing grades\n",
    "    data = data.dropna(subset = grade_col)\n",
    "    # Convert U grade to 0\n",
    "    data.loc[data[grade_col] == \"U\", grade_col] = \"0\"\n",
    "    # Convert grades to numeric from string format\n",
    "    data = data[data[grade_col].isin([str(x) for x in (range(0, 10))])]\n",
    "    data[grade_col] = data[grade_col].astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc29d624",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_gcse_data(df = pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes raw GCSE exam data (2017-2020 files), filters it\n",
    "    appropriately and processes it. \n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of raw GCSE data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy to prevent in-place changes\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Make cols lowercase\n",
    "    data.columns = [x.lower() for x in data.columns]\n",
    "    \n",
    "    # Reformat examseries to year col\n",
    "    data[\"year\"] = data.examseries.apply(lambda x: x.split()[1])\n",
    "    \n",
    "    # Remove candidates who were not 16 on 31st August\n",
    "    data = data.query(\"yearendage == 16\")\n",
    "    # Remove private candidates\n",
    "    data = data.query(\"privatecandidate == False\")\n",
    "    # Commented out below since all True in synthetic data\n",
    "    # Remove partial absentees\n",
    "#     data = data.query(\"partialabsence == False\")\n",
    "    # Remove candidates without prior attainment or that weren't matched in NPD\n",
    "    data = data.dropna(subset = [\"normalisedks2score\", \"npdmatchround\"])\n",
    "    \n",
    "    # Remove candidates with 0 prior attainment (errors in data)\n",
    "    data = data[data.normalisedks2score > 0]\n",
    "    \n",
    "    # Remove non-reformed GCSEs\n",
    "    data = data[data.reformphase.isin(['Ofqual-regulated Phase 1 reformed GCSE FC',\n",
    "                                       'Ofqual-regulated Phase 2 reformed GCSE FC'])]\n",
    "    # Recode tier into foundation or not foundation\n",
    "    data.loc[data.tier != \"F\", \"tier\"] = \"Not F\"\n",
    "    \n",
    "    # Process grade column inplace\n",
    "    data = process_grades(data, grade_col = \"grade\")\n",
    "    \n",
    "    # Standardise the KS2 prior attainment to between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    data.normalisedks2score = scaler.fit_transform(data[['normalisedks2score']])\n",
    "    \n",
    "    # Get candidates who took at least 8 GCSEs\n",
    "    grouped = data.groupby(\"uidp\").count()\n",
    "    at_least_8 = set(grouped[grouped.examseries >= 8].index.to_list())\n",
    "    # Get candidates who took English and Maths\n",
    "    eng_math = set(data[data.jcqtitle.isin([\"Mathematics\", \"English language\"])].uidp)\n",
    "    # Get candidates who took English and Maths and >= 8 GCSEs\n",
    "    filtered_ids = at_least_8 & eng_math\n",
    "    # Beware that since this is simulated data, it's wrong\n",
    "    filtered = data[data.uidp.isin(filtered_ids)]\n",
    "    \n",
    "    # Select cols needed for modelling and dropnas\n",
    "    gcse_cols = [\"uidp\", \"year\", \"jcqtitle\", \"tier\", \"centretypedesc\",\n",
    "                 \"normalisedks2score\", \"grade\", \"centreassessmentgrade\"]\n",
    "    filtered = filtered[gcse_cols]\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59beabe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load and process all the GCSE exam data\n",
    "gcse_data = pd.DataFrame()\n",
    "# Iterate through files\n",
    "for file in gcse_files:\n",
    "    # Perform filtering/pre-processing\n",
    "    year_df = process_gcse_data(pd.read_csv(file))\n",
    "    # Process the CAG column too\n",
    "    if \"2020\" in file:\n",
    "        year_df = process_grades(year_df, \"centreassessmentgrade\")\n",
    "    # Create dummy value for other years\n",
    "    else:\n",
    "        year_df.centreassessmentgrade = np.NaN\n",
    "        \n",
    "    # Merge with other years\n",
    "    gcse_data = pd.concat([gcse_data, year_df])\n",
    "    # Delete var to save memory\n",
    "    del year_df\n",
    "# Reset index\n",
    "gcse_data = gcse_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe379c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NPD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1753693",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_npd(data = pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes raw NPD data (2017-2020 files), filters it\n",
    "    appropriately and processes it. \n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of raw NPD data\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Copy to prevent inplace changes\n",
    "    df = data.copy()\n",
    "    # Make cols lowercase\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    # Select the columns that are common across files\n",
    "    npd_cols = [\"uidp\", \"ks4_ealgrp_ptq_ee\", \"ks4_gender\"]\n",
    "    # Get the bases for the columns that change in suffix in each file\n",
    "    col_bases = [\"ethnicgroupmajor\", \"fsmeligible\", \"senprovisionmajor\"]\n",
    "    # Get the suffix part that changes\n",
    "    year_ending = int(file[-6:-4])\n",
    "    # Dynamically select those cols with changing suffixes\n",
    "    npd_cols.extend([col_base + f\"_spr{year_ending}\" for col_base in col_bases])\n",
    "    # Also add in most recent IDACI score\n",
    "    npd_cols.append(sorted([x for x in df.columns if \"idaciscore\" in x])[-1])\n",
    "    \n",
    "    # Select the needed columns\n",
    "    df = df[npd_cols]\n",
    "    # Add in year col\n",
    "    df[\"year\"] = f\"20{year_ending}\"\n",
    "    # Rename columns\n",
    "    clean_cols = [\"uidp\", \"eal\", \"gender\", \"ethnicity\",\n",
    "              \"fsm\", \"sen\", \"idaci\", \"year\"]\n",
    "    df.columns = clean_cols\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df8fa90",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_dict = dict()\n",
    "for file in npd_files:\n",
    "    col_dict[file[-8:-4]] = pd.read_csv(file).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59b5c1fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set(col_dict[\"2020\"]) & set(col_dict[\"2019\"]) & set(col_dict[\"2018\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c307597",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set(col_dict[\"2020\"]) - set(col_dict[\"2019\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d425709",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create df to store each year's data in\n",
    "npd_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through files\n",
    "for file in npd_files:\n",
    "    # Load data\n",
    "    df = pd.read_csv(file)\n",
    "    # Process the NPD data\n",
    "    df = process_npd(df)\n",
    "    # Combine into dataframe\n",
    "    npd_data = pd.concat([npd_data, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c99ad2",
   "metadata": {},
   "source": [
    "# Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f098cf",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def recode_cols(data = pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Takes processed merged GCSE exam and NPD data (2017-2020 files),\n",
    "    filters it appropriately and processes it. \n",
    "    It recodes several columns into fewer numbers of categories\n",
    "    to make modelling easier.\n",
    "    Returns a DataFrame with a reduced number of columns.\n",
    "    Full steps taken can be seen in code commenting or in\n",
    "    Methodology section of capstone.\n",
    "    --------------------------------------------------\n",
    "    df = DataFrame of merged NPD/GCSE data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy to prevent inplace changes\n",
    "    df = data.copy()\n",
    "    # Filter EAL to remove NAs or unclassifieds\n",
    "    df = df[df.eal.isin([1,2])]\n",
    "    # Filter ethnicity to remove unclassifieds/NaNs\n",
    "    df = df[df.ethnicity.isin([\"AOEG\", \"ASIA\", \"BLAC\", \"CHIN\",\n",
    "                          \"MIXD\", \"WHIT\"])]\n",
    "    # Filter and recode SEN to remove unclassifieds and make SEN/not SEN\n",
    "    df = df[df.sen.isin([\"1_NON\", \"2_SNS\", \"3_SS\"])]\n",
    "    df.loc[df.sen != \"1_NON\", \"sen\"] = \"SEN\"\n",
    "    df.loc[df.sen == \"1_NON\", \"sen\"] = \"No SEN\"\n",
    "    \n",
    "    # Drop remaining NaNs from FSM and IDACI cols\n",
    "    df = df.dropna(subset = [\"fsm\", \"idaci\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edb88ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join exam data with NPD data\n",
    "merged = npd_data.merge(gcse_data, on = [\"uidp\", \"year\"],\n",
    "                       how = \"inner\")\n",
    "\n",
    "# Recode columns and filter further\n",
    "df = recode_cols(merged)\n",
    "\n",
    "# Drop now unnecesary UIDP and year cols\n",
    "df = df.drop(columns = [\"year\", \"uidp\"])\n",
    "\n",
    "# Convert categorical cols to numerics\n",
    "categorical_cols = [\"eal\", \"gender\", \"ethnicity\", \"fsm\",\n",
    "               \"sen\", \"jcqtitle\", \"tier\", \"centretypedesc\"]\n",
    "# Fit encoder on categorical cols\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(df[categorical_cols])\n",
    "\n",
    "# Create a mapping for reference later\n",
    "mapping = {k:v for k, v in zip(categorical_cols, encoder.categories_)}\n",
    "\n",
    "# Convert categoricals to numerics\n",
    "df[categorical_cols] = encoder.transform(df[categorical_cols])\n",
    "\n",
    "# Split into treatment and control\n",
    "treatment = df[~df.centreassessmentgrade.isna()]\n",
    "control = df[df.centreassessmentgrade.isna()]\n",
    "# Old code, maybe useful for LGBM\n",
    "# df[categorical_cols] = df[categorical_cols].apply(pd.Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8430c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into labels and features\n",
    "X = np.array(control.iloc[:, :10], dtype = \"float32\")\n",
    "y = np.array(control.grade, dtype = \"float32\")\n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                   shuffle = True,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1126a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Quick EDA / Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55329892",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a7066e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11965e62ccc34671adbef79baaaeb316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060a72414b914f3b8937f1a6ffa78a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f221befc7844ed38725eb1048b34d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7098561f34e8475ab1d1b5c537da7fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = ProfileReport(df, title = \"eda_check\")\n",
    "report.to_file(\"eda_check.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0bb026",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d076847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to store model results in\n",
    "all_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6afcaf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, X_test,\n",
    "                  y_train, y_test,\n",
    "                  model, model_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to evaluate a model in terms of\n",
    "    train and test RMSE.\n",
    "    Returns a dataframe of model name and RMSEs.\n",
    "    --------------------------------------------------\n",
    "    X_train = np.array of X data, used to generate train RMSE\n",
    "    X_test = np.array of X data, used to generate test RMSE\n",
    "    y_train = np.array of y data, used to generate train RMSE\n",
    "    y_test = np.array of y data, used to generate test RMSE\n",
    "    model = fitted model instance to use with model.predict\n",
    "    model_name = str, name to save the model under\n",
    "    \"\"\"\n",
    "    # Generate predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    # Evaluate model\n",
    "    train_rmse = mean_squared_error(y_train, train_preds, squared = False)\n",
    "    test_rmse = mean_squared_error(y_test, test_preds, squared = False)\n",
    "\n",
    "    # Store results\n",
    "    results = pd.DataFrame({\"model\": model_name,\n",
    "                            \"train_rmse\": train_rmse,\n",
    "                            \"test_rmse\": test_rmse,\n",
    "                 }, index = [0])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6673845",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1398548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"linear\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e40bc6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc806e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(X_data,\n",
    "              layer_1_units = 64,\n",
    "              layer_2_units = 64,\n",
    "              batch_normalization = False,\n",
    "              loss = \"mse\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"mse\"]):\n",
    "    \"\"\"\n",
    "    Function to create artificial neural network. Dense layer\n",
    "    units can be specified, as can the use of batch normalization\n",
    "    in between the dense layers (this provides mild regularisation)\n",
    "    and may speed up training.\n",
    "    Returns a compiled Keras model.\n",
    "    --------------------------------------------------\n",
    "    X_data = np.array of X data, used to give input shape to model\n",
    "    layer_1_units = int, number of neurons in 1st hidden layer\n",
    "    layer_2_units = int, number of neurons in 2nd hidden layer\n",
    "    batch_normalization = bool, batch normalize between hidden layers \n",
    "    if true\n",
    "    loss = str, name of loss function to use\n",
    "    optimizer = str or keras.Optimzer object, optimizer to use\n",
    "    metrics = list of strings, evaluation metrics to use\n",
    "    \"\"\"\n",
    "    # Build model\n",
    "    model = Sequential(name = \"MLP\")\n",
    "    # 1st Dense layer\n",
    "    model.add(Dense(units = layer_1_units, activation = \"relu\", input_shape = (X_data.shape[1], ),\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    \n",
    "    # Add batch normalization if desired\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    # 2nd Dense layer\n",
    "    model.add(Dense(units = layer_2_units, activation = \"relu\",\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    # Output layer\n",
    "    model.add(Dense(units = 1, activation = \"linear\",\n",
    "                   kernel_initializer = \"he_normal\"))\n",
    "    # Compile model\n",
    "    model.compile(**compile_hp)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55079002",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hyperparams used during modelling\n",
    "# Compilation hyperparams\n",
    "compile_hp = dict()\n",
    "compile_hp[\"loss\"] = \"mse\"\n",
    "compile_hp[\"optimizer\"] = optimizers.Adam(learning_rate = 0.001)\n",
    "compile_hp[\"metrics\"] = [\"mse\"]\n",
    "\n",
    "# Fitting hyperparams\n",
    "fit_hp = dict()\n",
    "fit_hp[\"batch_size\"] = 32\n",
    "fit_hp[\"epochs\"] = 200\n",
    "fit_hp[\"validation_split\"] = 0.2\n",
    "# Create callback to select the best model\n",
    "fit_hp[\"callbacks\"] = EarlyStopping(monitor = \"val_loss\",\n",
    "                                         mode = \"min\",\n",
    "                                         restore_best_weights = True,\n",
    "                                         patience = 25)\n",
    "\n",
    "# Eliminate verbose to have a neater notebook \n",
    "fit_hp[\"verbose\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2e941",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a588d22d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:19:54.296737: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-23 17:19:54.296851: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:19:54.669986: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-23 17:19:54.890119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 1s - loss: 35.4301 - mse: 35.4301 - val_loss: 105.5467 - val_mse: 105.5467 - 526ms/epoch - 175ms/step\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 31.6174 - mse: 31.6174 - val_loss: 73.1889 - val_mse: 73.1889 - 31ms/epoch - 10ms/step\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 27.8028 - mse: 27.8028 - val_loss: 50.8299 - val_mse: 50.8299 - 31ms/epoch - 10ms/step\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 24.8443 - mse: 24.8443 - val_loss: 35.7308 - val_mse: 35.7308 - 32ms/epoch - 11ms/step\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 21.7518 - mse: 21.7518 - val_loss: 25.5623 - val_mse: 25.5623 - 31ms/epoch - 10ms/step\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:19:55.161595: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 19.2080 - mse: 19.2080 - val_loss: 18.7571 - val_mse: 18.7571 - 31ms/epoch - 10ms/step\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 17.3442 - mse: 17.3442 - val_loss: 14.3797 - val_mse: 14.3797 - 31ms/epoch - 10ms/step\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 14.9395 - mse: 14.9395 - val_loss: 11.7763 - val_mse: 11.7762 - 36ms/epoch - 12ms/step\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 13.3005 - mse: 13.3005 - val_loss: 10.6008 - val_mse: 10.6008 - 31ms/epoch - 10ms/step\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 11.9022 - mse: 11.9022 - val_loss: 10.2842 - val_mse: 10.2842 - 31ms/epoch - 10ms/step\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 10.7360 - mse: 10.7360 - val_loss: 10.5100 - val_mse: 10.5100 - 28ms/epoch - 9ms/step\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 9.3650 - mse: 9.3650 - val_loss: 11.0057 - val_mse: 11.0057 - 28ms/epoch - 9ms/step\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 8.2038 - mse: 8.2038 - val_loss: 11.6204 - val_mse: 11.6204 - 30ms/epoch - 10ms/step\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 8.0011 - mse: 8.0011 - val_loss: 12.2988 - val_mse: 12.2988 - 30ms/epoch - 10ms/step\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 7.0463 - mse: 7.0463 - val_loss: 12.7949 - val_mse: 12.7949 - 31ms/epoch - 10ms/step\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 7.2173 - mse: 7.2173 - val_loss: 13.1254 - val_mse: 13.1254 - 28ms/epoch - 9ms/step\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 6.2974 - mse: 6.2974 - val_loss: 13.2231 - val_mse: 13.2231 - 28ms/epoch - 9ms/step\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 5.5226 - mse: 5.5226 - val_loss: 13.0743 - val_mse: 13.0743 - 28ms/epoch - 9ms/step\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 5.1403 - mse: 5.1403 - val_loss: 12.6483 - val_mse: 12.6483 - 28ms/epoch - 9ms/step\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 5.0092 - mse: 5.0092 - val_loss: 12.2502 - val_mse: 12.2502 - 28ms/epoch - 9ms/step\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 4.8327 - mse: 4.8327 - val_loss: 11.7165 - val_mse: 11.7165 - 28ms/epoch - 9ms/step\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 4.3470 - mse: 4.3470 - val_loss: 11.1777 - val_mse: 11.1777 - 28ms/epoch - 9ms/step\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 4.7121 - mse: 4.7121 - val_loss: 10.6777 - val_mse: 10.6777 - 28ms/epoch - 9ms/step\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 4.1752 - mse: 4.1752 - val_loss: 10.0531 - val_mse: 10.0531 - 31ms/epoch - 10ms/step\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 4.3647 - mse: 4.3647 - val_loss: 9.4943 - val_mse: 9.4943 - 31ms/epoch - 10ms/step\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 4.1385 - mse: 4.1385 - val_loss: 8.9356 - val_mse: 8.9356 - 31ms/epoch - 10ms/step\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 4.1750 - mse: 4.1750 - val_loss: 8.6359 - val_mse: 8.6359 - 32ms/epoch - 11ms/step\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 4.2453 - mse: 4.2453 - val_loss: 8.2754 - val_mse: 8.2754 - 31ms/epoch - 10ms/step\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 4.4069 - mse: 4.4069 - val_loss: 7.9542 - val_mse: 7.9542 - 31ms/epoch - 10ms/step\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 3.6484 - mse: 3.6484 - val_loss: 7.5879 - val_mse: 7.5879 - 31ms/epoch - 10ms/step\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 4.3680 - mse: 4.3680 - val_loss: 7.3166 - val_mse: 7.3166 - 31ms/epoch - 10ms/step\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 3.6099 - mse: 3.6099 - val_loss: 7.1578 - val_mse: 7.1578 - 31ms/epoch - 10ms/step\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 3.8450 - mse: 3.8450 - val_loss: 6.9840 - val_mse: 6.9840 - 32ms/epoch - 11ms/step\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 3.7298 - mse: 3.7298 - val_loss: 6.9080 - val_mse: 6.9080 - 33ms/epoch - 11ms/step\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 3.7813 - mse: 3.7813 - val_loss: 6.8145 - val_mse: 6.8145 - 30ms/epoch - 10ms/step\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 3.6873 - mse: 3.6873 - val_loss: 6.7370 - val_mse: 6.7370 - 31ms/epoch - 10ms/step\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 3.6575 - mse: 3.6575 - val_loss: 6.7031 - val_mse: 6.7031 - 31ms/epoch - 10ms/step\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 3.5133 - mse: 3.5133 - val_loss: 6.6690 - val_mse: 6.6690 - 31ms/epoch - 10ms/step\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 3.5878 - mse: 3.5878 - val_loss: 6.5566 - val_mse: 6.5566 - 32ms/epoch - 11ms/step\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 3.6203 - mse: 3.6203 - val_loss: 6.4670 - val_mse: 6.4670 - 34ms/epoch - 11ms/step\n",
      "Epoch 41/200\n",
      "3/3 - 0s - loss: 3.5360 - mse: 3.5360 - val_loss: 6.3720 - val_mse: 6.3720 - 31ms/epoch - 10ms/step\n",
      "Epoch 42/200\n",
      "3/3 - 0s - loss: 3.3455 - mse: 3.3455 - val_loss: 6.3345 - val_mse: 6.3345 - 31ms/epoch - 10ms/step\n",
      "Epoch 43/200\n",
      "3/3 - 0s - loss: 3.4069 - mse: 3.4069 - val_loss: 6.2793 - val_mse: 6.2793 - 31ms/epoch - 10ms/step\n",
      "Epoch 44/200\n",
      "3/3 - 0s - loss: 3.0527 - mse: 3.0527 - val_loss: 6.2571 - val_mse: 6.2571 - 32ms/epoch - 11ms/step\n",
      "Epoch 45/200\n",
      "3/3 - 0s - loss: 3.2162 - mse: 3.2162 - val_loss: 6.2306 - val_mse: 6.2306 - 31ms/epoch - 10ms/step\n",
      "Epoch 46/200\n",
      "3/3 - 0s - loss: 3.5881 - mse: 3.5881 - val_loss: 6.2022 - val_mse: 6.2022 - 32ms/epoch - 11ms/step\n",
      "Epoch 47/200\n",
      "3/3 - 0s - loss: 3.0952 - mse: 3.0952 - val_loss: 6.1674 - val_mse: 6.1674 - 32ms/epoch - 11ms/step\n",
      "Epoch 48/200\n",
      "3/3 - 0s - loss: 3.1226 - mse: 3.1226 - val_loss: 6.1457 - val_mse: 6.1457 - 32ms/epoch - 11ms/step\n",
      "Epoch 49/200\n",
      "3/3 - 0s - loss: 3.2371 - mse: 3.2371 - val_loss: 6.1476 - val_mse: 6.1476 - 28ms/epoch - 9ms/step\n",
      "Epoch 50/200\n",
      "3/3 - 0s - loss: 3.1864 - mse: 3.1864 - val_loss: 6.1336 - val_mse: 6.1336 - 32ms/epoch - 11ms/step\n",
      "Epoch 51/200\n",
      "3/3 - 0s - loss: 3.9778 - mse: 3.9778 - val_loss: 6.1449 - val_mse: 6.1449 - 28ms/epoch - 9ms/step\n",
      "Epoch 52/200\n",
      "3/3 - 0s - loss: 3.5181 - mse: 3.5181 - val_loss: 6.1226 - val_mse: 6.1226 - 32ms/epoch - 11ms/step\n",
      "Epoch 53/200\n",
      "3/3 - 0s - loss: 3.1754 - mse: 3.1754 - val_loss: 6.0906 - val_mse: 6.0906 - 32ms/epoch - 11ms/step\n",
      "Epoch 54/200\n",
      "3/3 - 0s - loss: 3.1273 - mse: 3.1273 - val_loss: 6.1001 - val_mse: 6.1001 - 29ms/epoch - 10ms/step\n",
      "Epoch 55/200\n",
      "3/3 - 0s - loss: 2.9782 - mse: 2.9782 - val_loss: 6.0993 - val_mse: 6.0993 - 28ms/epoch - 9ms/step\n",
      "Epoch 56/200\n",
      "3/3 - 0s - loss: 3.1770 - mse: 3.1770 - val_loss: 6.0785 - val_mse: 6.0785 - 34ms/epoch - 11ms/step\n",
      "Epoch 57/200\n",
      "3/3 - 0s - loss: 3.1488 - mse: 3.1488 - val_loss: 6.0578 - val_mse: 6.0578 - 36ms/epoch - 12ms/step\n",
      "Epoch 58/200\n",
      "3/3 - 0s - loss: 2.9695 - mse: 2.9695 - val_loss: 6.0472 - val_mse: 6.0472 - 35ms/epoch - 12ms/step\n",
      "Epoch 59/200\n",
      "3/3 - 0s - loss: 2.9713 - mse: 2.9713 - val_loss: 6.0224 - val_mse: 6.0224 - 38ms/epoch - 13ms/step\n",
      "Epoch 60/200\n",
      "3/3 - 0s - loss: 2.9138 - mse: 2.9138 - val_loss: 5.9956 - val_mse: 5.9956 - 34ms/epoch - 11ms/step\n",
      "Epoch 61/200\n",
      "3/3 - 0s - loss: 2.9827 - mse: 2.9827 - val_loss: 5.9635 - val_mse: 5.9635 - 33ms/epoch - 11ms/step\n",
      "Epoch 62/200\n",
      "3/3 - 0s - loss: 2.9717 - mse: 2.9717 - val_loss: 5.9439 - val_mse: 5.9439 - 34ms/epoch - 11ms/step\n",
      "Epoch 63/200\n",
      "3/3 - 0s - loss: 3.1801 - mse: 3.1801 - val_loss: 5.9556 - val_mse: 5.9556 - 30ms/epoch - 10ms/step\n",
      "Epoch 64/200\n",
      "3/3 - 0s - loss: 2.9843 - mse: 2.9843 - val_loss: 5.9441 - val_mse: 5.9441 - 31ms/epoch - 10ms/step\n",
      "Epoch 65/200\n",
      "3/3 - 0s - loss: 3.0650 - mse: 3.0650 - val_loss: 5.9402 - val_mse: 5.9402 - 34ms/epoch - 11ms/step\n",
      "Epoch 66/200\n",
      "3/3 - 0s - loss: 3.0330 - mse: 3.0330 - val_loss: 5.9463 - val_mse: 5.9463 - 29ms/epoch - 10ms/step\n",
      "Epoch 67/200\n",
      "3/3 - 0s - loss: 3.1524 - mse: 3.1524 - val_loss: 5.9252 - val_mse: 5.9252 - 32ms/epoch - 11ms/step\n",
      "Epoch 68/200\n",
      "3/3 - 0s - loss: 2.7491 - mse: 2.7491 - val_loss: 5.9261 - val_mse: 5.9261 - 29ms/epoch - 10ms/step\n",
      "Epoch 69/200\n",
      "3/3 - 0s - loss: 2.6942 - mse: 2.6942 - val_loss: 5.9003 - val_mse: 5.9003 - 32ms/epoch - 11ms/step\n",
      "Epoch 70/200\n",
      "3/3 - 0s - loss: 3.2741 - mse: 3.2741 - val_loss: 5.8584 - val_mse: 5.8584 - 32ms/epoch - 11ms/step\n",
      "Epoch 71/200\n",
      "3/3 - 0s - loss: 2.8783 - mse: 2.8783 - val_loss: 5.8406 - val_mse: 5.8406 - 31ms/epoch - 10ms/step\n",
      "Epoch 72/200\n",
      "3/3 - 0s - loss: 2.7705 - mse: 2.7705 - val_loss: 5.8343 - val_mse: 5.8343 - 31ms/epoch - 10ms/step\n",
      "Epoch 73/200\n",
      "3/3 - 0s - loss: 2.6957 - mse: 2.6957 - val_loss: 5.8449 - val_mse: 5.8449 - 30ms/epoch - 10ms/step\n",
      "Epoch 74/200\n",
      "3/3 - 0s - loss: 2.8141 - mse: 2.8141 - val_loss: 5.8566 - val_mse: 5.8566 - 28ms/epoch - 9ms/step\n",
      "Epoch 75/200\n",
      "3/3 - 0s - loss: 2.9860 - mse: 2.9860 - val_loss: 5.8764 - val_mse: 5.8764 - 28ms/epoch - 9ms/step\n",
      "Epoch 76/200\n",
      "3/3 - 0s - loss: 3.5524 - mse: 3.5524 - val_loss: 5.8776 - val_mse: 5.8776 - 28ms/epoch - 9ms/step\n",
      "Epoch 77/200\n",
      "3/3 - 0s - loss: 2.7762 - mse: 2.7762 - val_loss: 5.8811 - val_mse: 5.8811 - 30ms/epoch - 10ms/step\n",
      "Epoch 78/200\n",
      "3/3 - 0s - loss: 2.9716 - mse: 2.9716 - val_loss: 5.8729 - val_mse: 5.8729 - 28ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "3/3 - 0s - loss: 2.6666 - mse: 2.6666 - val_loss: 5.8638 - val_mse: 5.8638 - 30ms/epoch - 10ms/step\n",
      "Epoch 80/200\n",
      "3/3 - 0s - loss: 2.9854 - mse: 2.9854 - val_loss: 5.8453 - val_mse: 5.8453 - 31ms/epoch - 10ms/step\n",
      "Epoch 81/200\n",
      "3/3 - 0s - loss: 2.8774 - mse: 2.8774 - val_loss: 5.8236 - val_mse: 5.8236 - 33ms/epoch - 11ms/step\n",
      "Epoch 82/200\n",
      "3/3 - 0s - loss: 2.8302 - mse: 2.8302 - val_loss: 5.8345 - val_mse: 5.8345 - 31ms/epoch - 10ms/step\n",
      "Epoch 83/200\n",
      "3/3 - 0s - loss: 2.7344 - mse: 2.7344 - val_loss: 5.8675 - val_mse: 5.8675 - 28ms/epoch - 9ms/step\n",
      "Epoch 84/200\n",
      "3/3 - 0s - loss: 2.6378 - mse: 2.6378 - val_loss: 5.9082 - val_mse: 5.9082 - 30ms/epoch - 10ms/step\n",
      "Epoch 85/200\n",
      "3/3 - 0s - loss: 2.3327 - mse: 2.3327 - val_loss: 5.9474 - val_mse: 5.9474 - 29ms/epoch - 10ms/step\n",
      "Epoch 86/200\n",
      "3/3 - 0s - loss: 2.8361 - mse: 2.8361 - val_loss: 5.9917 - val_mse: 5.9917 - 29ms/epoch - 10ms/step\n",
      "Epoch 87/200\n",
      "3/3 - 0s - loss: 2.8071 - mse: 2.8071 - val_loss: 6.0313 - val_mse: 6.0313 - 30ms/epoch - 10ms/step\n",
      "Epoch 88/200\n",
      "3/3 - 0s - loss: 2.5572 - mse: 2.5572 - val_loss: 6.0585 - val_mse: 6.0585 - 30ms/epoch - 10ms/step\n",
      "Epoch 89/200\n",
      "3/3 - 0s - loss: 2.6485 - mse: 2.6485 - val_loss: 6.0741 - val_mse: 6.0741 - 32ms/epoch - 11ms/step\n",
      "Epoch 90/200\n",
      "3/3 - 0s - loss: 2.6504 - mse: 2.6504 - val_loss: 6.0699 - val_mse: 6.0699 - 31ms/epoch - 10ms/step\n",
      "Epoch 91/200\n",
      "3/3 - 0s - loss: 3.0469 - mse: 3.0469 - val_loss: 6.0770 - val_mse: 6.0770 - 32ms/epoch - 11ms/step\n",
      "Epoch 92/200\n",
      "3/3 - 0s - loss: 2.5043 - mse: 2.5043 - val_loss: 6.1059 - val_mse: 6.1059 - 32ms/epoch - 11ms/step\n",
      "Epoch 93/200\n",
      "3/3 - 0s - loss: 2.9052 - mse: 2.9052 - val_loss: 6.1313 - val_mse: 6.1313 - 31ms/epoch - 10ms/step\n",
      "Epoch 94/200\n",
      "3/3 - 0s - loss: 2.8433 - mse: 2.8433 - val_loss: 6.0937 - val_mse: 6.0937 - 31ms/epoch - 10ms/step\n",
      "Epoch 95/200\n",
      "3/3 - 0s - loss: 2.4995 - mse: 2.4995 - val_loss: 6.0816 - val_mse: 6.0816 - 29ms/epoch - 10ms/step\n",
      "Epoch 96/200\n",
      "3/3 - 0s - loss: 2.8453 - mse: 2.8453 - val_loss: 6.0990 - val_mse: 6.0990 - 28ms/epoch - 9ms/step\n",
      "Epoch 97/200\n",
      "3/3 - 0s - loss: 2.2309 - mse: 2.2309 - val_loss: 6.0816 - val_mse: 6.0816 - 28ms/epoch - 9ms/step\n",
      "Epoch 98/200\n",
      "3/3 - 0s - loss: 2.8708 - mse: 2.8708 - val_loss: 6.0495 - val_mse: 6.0495 - 28ms/epoch - 9ms/step\n",
      "Epoch 99/200\n",
      "3/3 - 0s - loss: 2.6195 - mse: 2.6195 - val_loss: 6.0186 - val_mse: 6.0186 - 29ms/epoch - 10ms/step\n",
      "Epoch 100/200\n",
      "3/3 - 0s - loss: 2.7783 - mse: 2.7783 - val_loss: 6.0151 - val_mse: 6.0151 - 29ms/epoch - 10ms/step\n",
      "Epoch 101/200\n",
      "3/3 - 0s - loss: 2.4840 - mse: 2.4840 - val_loss: 6.0236 - val_mse: 6.0236 - 29ms/epoch - 10ms/step\n",
      "Epoch 102/200\n",
      "3/3 - 0s - loss: 2.3163 - mse: 2.3163 - val_loss: 6.0086 - val_mse: 6.0086 - 31ms/epoch - 10ms/step\n",
      "Epoch 103/200\n",
      "3/3 - 0s - loss: 2.9539 - mse: 2.9539 - val_loss: 5.9982 - val_mse: 5.9982 - 31ms/epoch - 10ms/step\n",
      "Epoch 104/200\n",
      "3/3 - 0s - loss: 2.4310 - mse: 2.4310 - val_loss: 5.9897 - val_mse: 5.9897 - 30ms/epoch - 10ms/step\n",
      "Epoch 105/200\n",
      "3/3 - 0s - loss: 2.6652 - mse: 2.6652 - val_loss: 5.9638 - val_mse: 5.9638 - 30ms/epoch - 10ms/step\n",
      "Epoch 106/200\n",
      "3/3 - 0s - loss: 3.0563 - mse: 3.0563 - val_loss: 5.9443 - val_mse: 5.9443 - 33ms/epoch - 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:19:58.634692: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 64\n",
    "layer_2_units = 64\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = True\n",
    "\n",
    "# Build and compile model\n",
    "model = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"neural_network-64_64_init_bn\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156d4613",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c211bbe1",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 - 0s - loss: 14.6642 - mse: 14.6642 - val_loss: 18.0414 - val_mse: 18.0414 - 289ms/epoch - 96ms/step\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 14.8874 - mse: 14.8874 - val_loss: 8.2808 - val_mse: 8.2808 - 27ms/epoch - 9ms/step\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:19:58.882918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 17:19:59.012326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 6.3675 - mse: 6.3675 - val_loss: 11.7070 - val_mse: 11.7070 - 26ms/epoch - 9ms/step\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 6.1703 - mse: 6.1703 - val_loss: 5.9830 - val_mse: 5.9830 - 27ms/epoch - 9ms/step\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 5.6631 - mse: 5.6631 - val_loss: 6.0599 - val_mse: 6.0599 - 25ms/epoch - 8ms/step\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 4.5408 - mse: 4.5408 - val_loss: 7.9040 - val_mse: 7.9040 - 27ms/epoch - 9ms/step\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 4.5045 - mse: 4.5045 - val_loss: 5.8169 - val_mse: 5.8169 - 30ms/epoch - 10ms/step\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 4.8580 - mse: 4.8580 - val_loss: 5.9140 - val_mse: 5.9140 - 27ms/epoch - 9ms/step\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 4.3725 - mse: 4.3725 - val_loss: 7.8202 - val_mse: 7.8202 - 25ms/epoch - 8ms/step\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 4.4612 - mse: 4.4612 - val_loss: 6.3789 - val_mse: 6.3789 - 26ms/epoch - 9ms/step\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 3.6741 - mse: 3.6741 - val_loss: 6.0085 - val_mse: 6.0085 - 27ms/epoch - 9ms/step\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 3.9109 - mse: 3.9109 - val_loss: 6.7805 - val_mse: 6.7805 - 26ms/epoch - 9ms/step\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 3.6895 - mse: 3.6895 - val_loss: 7.5249 - val_mse: 7.5249 - 26ms/epoch - 9ms/step\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 3.5499 - mse: 3.5499 - val_loss: 6.6134 - val_mse: 6.6134 - 24ms/epoch - 8ms/step\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 3.5648 - mse: 3.5648 - val_loss: 6.8765 - val_mse: 6.8765 - 24ms/epoch - 8ms/step\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 3.3853 - mse: 3.3853 - val_loss: 7.7478 - val_mse: 7.7478 - 24ms/epoch - 8ms/step\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 3.4230 - mse: 3.4230 - val_loss: 6.9477 - val_mse: 6.9477 - 25ms/epoch - 8ms/step\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 3.3207 - mse: 3.3207 - val_loss: 6.6758 - val_mse: 6.6758 - 24ms/epoch - 8ms/step\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 3.2286 - mse: 3.2286 - val_loss: 7.0867 - val_mse: 7.0867 - 24ms/epoch - 8ms/step\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 3.2051 - mse: 3.2051 - val_loss: 6.7538 - val_mse: 6.7538 - 25ms/epoch - 8ms/step\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 3.2067 - mse: 3.2067 - val_loss: 6.3876 - val_mse: 6.3876 - 24ms/epoch - 8ms/step\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 3.2363 - mse: 3.2363 - val_loss: 6.9742 - val_mse: 6.9742 - 24ms/epoch - 8ms/step\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 3.0645 - mse: 3.0645 - val_loss: 6.7823 - val_mse: 6.7823 - 24ms/epoch - 8ms/step\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 3.0549 - mse: 3.0549 - val_loss: 6.7729 - val_mse: 6.7729 - 24ms/epoch - 8ms/step\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 3.0299 - mse: 3.0299 - val_loss: 6.8417 - val_mse: 6.8417 - 24ms/epoch - 8ms/step\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 2.9735 - mse: 2.9735 - val_loss: 7.2312 - val_mse: 7.2312 - 25ms/epoch - 8ms/step\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 2.9736 - mse: 2.9736 - val_loss: 7.1093 - val_mse: 7.1093 - 26ms/epoch - 9ms/step\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 2.9557 - mse: 2.9557 - val_loss: 6.9086 - val_mse: 6.9086 - 25ms/epoch - 8ms/step\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 2.9565 - mse: 2.9565 - val_loss: 6.8857 - val_mse: 6.8857 - 25ms/epoch - 8ms/step\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 3.0036 - mse: 3.0036 - val_loss: 7.3017 - val_mse: 7.3017 - 24ms/epoch - 8ms/step\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 2.8675 - mse: 2.8675 - val_loss: 6.6215 - val_mse: 6.6215 - 25ms/epoch - 8ms/step\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 2.8946 - mse: 2.8946 - val_loss: 6.5799 - val_mse: 6.5799 - 27ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:19:59.902471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 64\n",
    "layer_2_units = 128\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = False\n",
    "\n",
    "# Build and compile model\n",
    "model = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"neural_network-64_128\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fb215",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff84ba3f",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 - 0s - loss: 20.1776 - mse: 20.1776 - val_loss: 27.4567 - val_mse: 27.4567 - 282ms/epoch - 94ms/step\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 21.1520 - mse: 21.1520 - val_loss: 15.2873 - val_mse: 15.2873 - 27ms/epoch - 9ms/step\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:20:00.114985: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 17:20:00.243560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 14.4204 - mse: 14.4204 - val_loss: 8.9692 - val_mse: 8.9692 - 28ms/epoch - 9ms/step\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 8.3185 - mse: 8.3185 - val_loss: 9.9003 - val_mse: 9.9003 - 24ms/epoch - 8ms/step\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 8.2991 - mse: 8.2991 - val_loss: 7.3524 - val_mse: 7.3524 - 26ms/epoch - 9ms/step\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 6.7945 - mse: 6.7945 - val_loss: 9.3715 - val_mse: 9.3715 - 24ms/epoch - 8ms/step\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 5.1064 - mse: 5.1064 - val_loss: 5.7419 - val_mse: 5.7419 - 26ms/epoch - 9ms/step\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 5.9638 - mse: 5.9638 - val_loss: 5.8756 - val_mse: 5.8756 - 24ms/epoch - 8ms/step\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 3.9530 - mse: 3.9530 - val_loss: 8.4094 - val_mse: 8.4094 - 24ms/epoch - 8ms/step\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 4.6990 - mse: 4.6990 - val_loss: 6.8237 - val_mse: 6.8237 - 26ms/epoch - 9ms/step\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 3.8229 - mse: 3.8229 - val_loss: 6.2162 - val_mse: 6.2162 - 24ms/epoch - 8ms/step\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 4.1915 - mse: 4.1915 - val_loss: 6.5656 - val_mse: 6.5656 - 25ms/epoch - 8ms/step\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 3.4890 - mse: 3.4890 - val_loss: 8.1565 - val_mse: 8.1565 - 24ms/epoch - 8ms/step\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 3.9419 - mse: 3.9419 - val_loss: 6.8048 - val_mse: 6.8048 - 24ms/epoch - 8ms/step\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 3.4603 - mse: 3.4603 - val_loss: 6.1022 - val_mse: 6.1022 - 24ms/epoch - 8ms/step\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 3.6371 - mse: 3.6371 - val_loss: 6.7469 - val_mse: 6.7469 - 24ms/epoch - 8ms/step\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 3.3507 - mse: 3.3507 - val_loss: 7.0103 - val_mse: 7.0103 - 24ms/epoch - 8ms/step\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 3.2083 - mse: 3.2083 - val_loss: 6.0941 - val_mse: 6.0941 - 24ms/epoch - 8ms/step\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 3.2024 - mse: 3.2024 - val_loss: 6.0488 - val_mse: 6.0488 - 24ms/epoch - 8ms/step\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 3.0980 - mse: 3.0980 - val_loss: 6.3865 - val_mse: 6.3865 - 25ms/epoch - 8ms/step\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 2.9402 - mse: 2.9402 - val_loss: 6.9112 - val_mse: 6.9112 - 25ms/epoch - 8ms/step\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 3.0111 - mse: 3.0111 - val_loss: 6.7721 - val_mse: 6.7721 - 26ms/epoch - 9ms/step\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 2.9268 - mse: 2.9268 - val_loss: 6.3351 - val_mse: 6.3351 - 26ms/epoch - 9ms/step\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 2.9681 - mse: 2.9681 - val_loss: 6.7601 - val_mse: 6.7601 - 26ms/epoch - 9ms/step\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 2.8915 - mse: 2.8915 - val_loss: 6.9894 - val_mse: 6.9894 - 25ms/epoch - 8ms/step\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 2.8825 - mse: 2.8825 - val_loss: 6.6791 - val_mse: 6.6791 - 24ms/epoch - 8ms/step\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 2.7818 - mse: 2.7818 - val_loss: 7.1410 - val_mse: 7.1410 - 24ms/epoch - 8ms/step\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 2.9970 - mse: 2.9970 - val_loss: 7.5206 - val_mse: 7.5206 - 70ms/epoch - 23ms/step\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 2.8921 - mse: 2.8921 - val_loss: 6.4071 - val_mse: 6.4071 - 35ms/epoch - 12ms/step\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 2.7747 - mse: 2.7747 - val_loss: 6.7458 - val_mse: 6.7458 - 24ms/epoch - 8ms/step\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 2.6912 - mse: 2.6912 - val_loss: 6.9195 - val_mse: 6.9195 - 24ms/epoch - 8ms/step\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 2.6736 - mse: 2.6736 - val_loss: 6.5489 - val_mse: 6.5489 - 25ms/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:20:01.177584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 128\n",
    "layer_2_units = 128\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = False\n",
    "\n",
    "# Build and compile model\n",
    "model = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"neural_network-128_128\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c51782",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### NN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da3eef3c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:20:01.461789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-23 17:20:01.655970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 21.8550 - mse: 21.8550 - val_loss: 11.3112 - val_mse: 11.3112 - 413ms/epoch - 138ms/step\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 18.9942 - mse: 18.9942 - val_loss: 17.8961 - val_mse: 17.8961 - 29ms/epoch - 10ms/step\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 15.2380 - mse: 15.2380 - val_loss: 32.3568 - val_mse: 32.3568 - 28ms/epoch - 9ms/step\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 12.8583 - mse: 12.8583 - val_loss: 49.4785 - val_mse: 49.4785 - 28ms/epoch - 9ms/step\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 10.2925 - mse: 10.2925 - val_loss: 59.5824 - val_mse: 59.5824 - 28ms/epoch - 9ms/step\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 8.6520 - mse: 8.6520 - val_loss: 62.2779 - val_mse: 62.2779 - 28ms/epoch - 9ms/step\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 7.9952 - mse: 7.9952 - val_loss: 54.7621 - val_mse: 54.7621 - 29ms/epoch - 10ms/step\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 6.5431 - mse: 6.5431 - val_loss: 41.8957 - val_mse: 41.8957 - 28ms/epoch - 9ms/step\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 5.5656 - mse: 5.5656 - val_loss: 30.3596 - val_mse: 30.3596 - 28ms/epoch - 9ms/step\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 4.8703 - mse: 4.8703 - val_loss: 21.9901 - val_mse: 21.9901 - 28ms/epoch - 9ms/step\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 4.3598 - mse: 4.3598 - val_loss: 16.0020 - val_mse: 16.0020 - 27ms/epoch - 9ms/step\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 4.2057 - mse: 4.2057 - val_loss: 12.5524 - val_mse: 12.5524 - 28ms/epoch - 9ms/step\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 4.1878 - mse: 4.1878 - val_loss: 11.2563 - val_mse: 11.2563 - 31ms/epoch - 10ms/step\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 3.6573 - mse: 3.6573 - val_loss: 11.0092 - val_mse: 11.0092 - 31ms/epoch - 10ms/step\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 3.5195 - mse: 3.5195 - val_loss: 10.8755 - val_mse: 10.8755 - 31ms/epoch - 10ms/step\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 3.7902 - mse: 3.7902 - val_loss: 10.8018 - val_mse: 10.8018 - 31ms/epoch - 10ms/step\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 3.3554 - mse: 3.3554 - val_loss: 10.2087 - val_mse: 10.2087 - 31ms/epoch - 10ms/step\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 3.0265 - mse: 3.0265 - val_loss: 9.8441 - val_mse: 9.8441 - 31ms/epoch - 10ms/step\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 3.1829 - mse: 3.1829 - val_loss: 9.4508 - val_mse: 9.4508 - 31ms/epoch - 10ms/step\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 3.3157 - mse: 3.3157 - val_loss: 8.8939 - val_mse: 8.8939 - 34ms/epoch - 11ms/step\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 3.3272 - mse: 3.3272 - val_loss: 8.4693 - val_mse: 8.4693 - 31ms/epoch - 10ms/step\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 3.2168 - mse: 3.2168 - val_loss: 8.1686 - val_mse: 8.1686 - 31ms/epoch - 10ms/step\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 3.0796 - mse: 3.0796 - val_loss: 8.0272 - val_mse: 8.0272 - 31ms/epoch - 10ms/step\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 3.1511 - mse: 3.1511 - val_loss: 7.9239 - val_mse: 7.9239 - 31ms/epoch - 10ms/step\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 2.8904 - mse: 2.8904 - val_loss: 7.7737 - val_mse: 7.7737 - 31ms/epoch - 10ms/step\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 3.4124 - mse: 3.4124 - val_loss: 7.5826 - val_mse: 7.5826 - 32ms/epoch - 11ms/step\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 3.1424 - mse: 3.1424 - val_loss: 7.5040 - val_mse: 7.5040 - 32ms/epoch - 11ms/step\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 2.7969 - mse: 2.7969 - val_loss: 7.4235 - val_mse: 7.4235 - 31ms/epoch - 10ms/step\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 2.9207 - mse: 2.9207 - val_loss: 7.2643 - val_mse: 7.2643 - 31ms/epoch - 10ms/step\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 2.8386 - mse: 2.8386 - val_loss: 7.1650 - val_mse: 7.1650 - 31ms/epoch - 10ms/step\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 3.0074 - mse: 3.0074 - val_loss: 7.0977 - val_mse: 7.0977 - 31ms/epoch - 10ms/step\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 2.9494 - mse: 2.9494 - val_loss: 7.0660 - val_mse: 7.0660 - 31ms/epoch - 10ms/step\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 2.9465 - mse: 2.9465 - val_loss: 7.0349 - val_mse: 7.0349 - 31ms/epoch - 10ms/step\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 2.8157 - mse: 2.8157 - val_loss: 7.0450 - val_mse: 7.0450 - 29ms/epoch - 10ms/step\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 2.8818 - mse: 2.8818 - val_loss: 7.0607 - val_mse: 7.0607 - 28ms/epoch - 9ms/step\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 3.0294 - mse: 3.0294 - val_loss: 7.0805 - val_mse: 7.0805 - 28ms/epoch - 9ms/step\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 2.7463 - mse: 2.7463 - val_loss: 7.0710 - val_mse: 7.0710 - 28ms/epoch - 9ms/step\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 3.0184 - mse: 3.0184 - val_loss: 7.0415 - val_mse: 7.0415 - 28ms/epoch - 9ms/step\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 2.5482 - mse: 2.5482 - val_loss: 7.0360 - val_mse: 7.0360 - 28ms/epoch - 9ms/step\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 2.5671 - mse: 2.5671 - val_loss: 7.0183 - val_mse: 7.0183 - 31ms/epoch - 10ms/step\n",
      "Epoch 41/200\n",
      "3/3 - 0s - loss: 2.7403 - mse: 2.7403 - val_loss: 6.9965 - val_mse: 6.9965 - 31ms/epoch - 10ms/step\n",
      "Epoch 42/200\n",
      "3/3 - 0s - loss: 2.5030 - mse: 2.5030 - val_loss: 6.9756 - val_mse: 6.9756 - 31ms/epoch - 10ms/step\n",
      "Epoch 43/200\n",
      "3/3 - 0s - loss: 2.6136 - mse: 2.6136 - val_loss: 6.9618 - val_mse: 6.9618 - 31ms/epoch - 10ms/step\n",
      "Epoch 44/200\n",
      "3/3 - 0s - loss: 2.7346 - mse: 2.7346 - val_loss: 6.9798 - val_mse: 6.9798 - 28ms/epoch - 9ms/step\n",
      "Epoch 45/200\n",
      "3/3 - 0s - loss: 2.4532 - mse: 2.4532 - val_loss: 6.9188 - val_mse: 6.9188 - 31ms/epoch - 10ms/step\n",
      "Epoch 46/200\n",
      "3/3 - 0s - loss: 2.4059 - mse: 2.4059 - val_loss: 6.8835 - val_mse: 6.8835 - 31ms/epoch - 10ms/step\n",
      "Epoch 47/200\n",
      "3/3 - 0s - loss: 2.8659 - mse: 2.8659 - val_loss: 6.8586 - val_mse: 6.8586 - 31ms/epoch - 10ms/step\n",
      "Epoch 48/200\n",
      "3/3 - 0s - loss: 2.8464 - mse: 2.8464 - val_loss: 6.8301 - val_mse: 6.8301 - 32ms/epoch - 11ms/step\n",
      "Epoch 49/200\n",
      "3/3 - 0s - loss: 2.8640 - mse: 2.8640 - val_loss: 6.8077 - val_mse: 6.8077 - 31ms/epoch - 10ms/step\n",
      "Epoch 50/200\n",
      "3/3 - 0s - loss: 2.4803 - mse: 2.4803 - val_loss: 6.8528 - val_mse: 6.8528 - 28ms/epoch - 9ms/step\n",
      "Epoch 51/200\n",
      "3/3 - 0s - loss: 2.7528 - mse: 2.7528 - val_loss: 6.8421 - val_mse: 6.8421 - 28ms/epoch - 9ms/step\n",
      "Epoch 52/200\n",
      "3/3 - 0s - loss: 2.6670 - mse: 2.6670 - val_loss: 6.7664 - val_mse: 6.7664 - 31ms/epoch - 10ms/step\n",
      "Epoch 53/200\n",
      "3/3 - 0s - loss: 2.6785 - mse: 2.6785 - val_loss: 6.7182 - val_mse: 6.7182 - 31ms/epoch - 10ms/step\n",
      "Epoch 54/200\n",
      "3/3 - 0s - loss: 2.8990 - mse: 2.8990 - val_loss: 6.7033 - val_mse: 6.7033 - 32ms/epoch - 11ms/step\n",
      "Epoch 55/200\n",
      "3/3 - 0s - loss: 2.6196 - mse: 2.6196 - val_loss: 6.6127 - val_mse: 6.6127 - 31ms/epoch - 10ms/step\n",
      "Epoch 56/200\n",
      "3/3 - 0s - loss: 2.5679 - mse: 2.5679 - val_loss: 6.5858 - val_mse: 6.5858 - 31ms/epoch - 10ms/step\n",
      "Epoch 57/200\n",
      "3/3 - 0s - loss: 2.6667 - mse: 2.6667 - val_loss: 6.6044 - val_mse: 6.6044 - 28ms/epoch - 9ms/step\n",
      "Epoch 58/200\n",
      "3/3 - 0s - loss: 2.2965 - mse: 2.2965 - val_loss: 6.5763 - val_mse: 6.5763 - 31ms/epoch - 10ms/step\n",
      "Epoch 59/200\n",
      "3/3 - 0s - loss: 2.4900 - mse: 2.4900 - val_loss: 6.5649 - val_mse: 6.5649 - 31ms/epoch - 10ms/step\n",
      "Epoch 60/200\n",
      "3/3 - 0s - loss: 2.5078 - mse: 2.5078 - val_loss: 6.5518 - val_mse: 6.5518 - 31ms/epoch - 10ms/step\n",
      "Epoch 61/200\n",
      "3/3 - 0s - loss: 2.5552 - mse: 2.5552 - val_loss: 6.5697 - val_mse: 6.5697 - 28ms/epoch - 9ms/step\n",
      "Epoch 62/200\n",
      "3/3 - 0s - loss: 2.8014 - mse: 2.8014 - val_loss: 6.5810 - val_mse: 6.5810 - 28ms/epoch - 9ms/step\n",
      "Epoch 63/200\n",
      "3/3 - 0s - loss: 2.3159 - mse: 2.3159 - val_loss: 6.5344 - val_mse: 6.5344 - 31ms/epoch - 10ms/step\n",
      "Epoch 64/200\n",
      "3/3 - 0s - loss: 2.5124 - mse: 2.5124 - val_loss: 6.5059 - val_mse: 6.5059 - 31ms/epoch - 10ms/step\n",
      "Epoch 65/200\n",
      "3/3 - 0s - loss: 2.5152 - mse: 2.5152 - val_loss: 6.4696 - val_mse: 6.4696 - 32ms/epoch - 11ms/step\n",
      "Epoch 66/200\n",
      "3/3 - 0s - loss: 2.6681 - mse: 2.6681 - val_loss: 6.4496 - val_mse: 6.4496 - 31ms/epoch - 10ms/step\n",
      "Epoch 67/200\n",
      "3/3 - 0s - loss: 2.4355 - mse: 2.4355 - val_loss: 6.4677 - val_mse: 6.4677 - 28ms/epoch - 9ms/step\n",
      "Epoch 68/200\n",
      "3/3 - 0s - loss: 2.6387 - mse: 2.6387 - val_loss: 6.4732 - val_mse: 6.4732 - 28ms/epoch - 9ms/step\n",
      "Epoch 69/200\n",
      "3/3 - 0s - loss: 2.3318 - mse: 2.3318 - val_loss: 6.4762 - val_mse: 6.4762 - 28ms/epoch - 9ms/step\n",
      "Epoch 70/200\n",
      "3/3 - 0s - loss: 2.4312 - mse: 2.4312 - val_loss: 6.4619 - val_mse: 6.4619 - 29ms/epoch - 10ms/step\n",
      "Epoch 71/200\n",
      "3/3 - 0s - loss: 2.5364 - mse: 2.5364 - val_loss: 6.4822 - val_mse: 6.4822 - 28ms/epoch - 9ms/step\n",
      "Epoch 72/200\n",
      "3/3 - 0s - loss: 2.3680 - mse: 2.3680 - val_loss: 6.5041 - val_mse: 6.5041 - 28ms/epoch - 9ms/step\n",
      "Epoch 73/200\n",
      "3/3 - 0s - loss: 2.4522 - mse: 2.4522 - val_loss: 6.5210 - val_mse: 6.5210 - 28ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "3/3 - 0s - loss: 2.3627 - mse: 2.3627 - val_loss: 6.5438 - val_mse: 6.5438 - 28ms/epoch - 9ms/step\n",
      "Epoch 75/200\n",
      "3/3 - 0s - loss: 2.3729 - mse: 2.3729 - val_loss: 6.5228 - val_mse: 6.5228 - 28ms/epoch - 9ms/step\n",
      "Epoch 76/200\n",
      "3/3 - 0s - loss: 2.2508 - mse: 2.2508 - val_loss: 6.5294 - val_mse: 6.5294 - 28ms/epoch - 9ms/step\n",
      "Epoch 77/200\n",
      "3/3 - 0s - loss: 2.4313 - mse: 2.4313 - val_loss: 6.5436 - val_mse: 6.5436 - 28ms/epoch - 9ms/step\n",
      "Epoch 78/200\n",
      "3/3 - 0s - loss: 2.3667 - mse: 2.3667 - val_loss: 6.5413 - val_mse: 6.5413 - 28ms/epoch - 9ms/step\n",
      "Epoch 79/200\n",
      "3/3 - 0s - loss: 2.3822 - mse: 2.3822 - val_loss: 6.4721 - val_mse: 6.4721 - 28ms/epoch - 9ms/step\n",
      "Epoch 80/200\n",
      "3/3 - 0s - loss: 2.3036 - mse: 2.3036 - val_loss: 6.4798 - val_mse: 6.4798 - 28ms/epoch - 9ms/step\n",
      "Epoch 81/200\n",
      "3/3 - 0s - loss: 2.2780 - mse: 2.2780 - val_loss: 6.4866 - val_mse: 6.4866 - 28ms/epoch - 9ms/step\n",
      "Epoch 82/200\n",
      "3/3 - 0s - loss: 2.3489 - mse: 2.3489 - val_loss: 6.5255 - val_mse: 6.5255 - 28ms/epoch - 9ms/step\n",
      "Epoch 83/200\n",
      "3/3 - 0s - loss: 2.2417 - mse: 2.2417 - val_loss: 6.4909 - val_mse: 6.4909 - 27ms/epoch - 9ms/step\n",
      "Epoch 84/200\n",
      "3/3 - 0s - loss: 2.4088 - mse: 2.4088 - val_loss: 6.4264 - val_mse: 6.4264 - 31ms/epoch - 10ms/step\n",
      "Epoch 85/200\n",
      "3/3 - 0s - loss: 2.4663 - mse: 2.4663 - val_loss: 6.4257 - val_mse: 6.4257 - 31ms/epoch - 10ms/step\n",
      "Epoch 86/200\n",
      "3/3 - 0s - loss: 2.4014 - mse: 2.4014 - val_loss: 6.3716 - val_mse: 6.3716 - 31ms/epoch - 10ms/step\n",
      "Epoch 87/200\n",
      "3/3 - 0s - loss: 2.3338 - mse: 2.3338 - val_loss: 6.3494 - val_mse: 6.3494 - 31ms/epoch - 10ms/step\n",
      "Epoch 88/200\n",
      "3/3 - 0s - loss: 2.4146 - mse: 2.4146 - val_loss: 6.3432 - val_mse: 6.3432 - 31ms/epoch - 10ms/step\n",
      "Epoch 89/200\n",
      "3/3 - 0s - loss: 2.3981 - mse: 2.3981 - val_loss: 6.3515 - val_mse: 6.3515 - 28ms/epoch - 9ms/step\n",
      "Epoch 90/200\n",
      "3/3 - 0s - loss: 2.4561 - mse: 2.4561 - val_loss: 6.3162 - val_mse: 6.3162 - 31ms/epoch - 10ms/step\n",
      "Epoch 91/200\n",
      "3/3 - 0s - loss: 2.1248 - mse: 2.1248 - val_loss: 6.2328 - val_mse: 6.2328 - 31ms/epoch - 10ms/step\n",
      "Epoch 92/200\n",
      "3/3 - 0s - loss: 2.0846 - mse: 2.0846 - val_loss: 6.1608 - val_mse: 6.1608 - 31ms/epoch - 10ms/step\n",
      "Epoch 93/200\n",
      "3/3 - 0s - loss: 2.3329 - mse: 2.3329 - val_loss: 6.1227 - val_mse: 6.1227 - 31ms/epoch - 10ms/step\n",
      "Epoch 94/200\n",
      "3/3 - 0s - loss: 2.2207 - mse: 2.2207 - val_loss: 6.1545 - val_mse: 6.1545 - 27ms/epoch - 9ms/step\n",
      "Epoch 95/200\n",
      "3/3 - 0s - loss: 2.0051 - mse: 2.0051 - val_loss: 6.1772 - val_mse: 6.1772 - 28ms/epoch - 9ms/step\n",
      "Epoch 96/200\n",
      "3/3 - 0s - loss: 2.2895 - mse: 2.2895 - val_loss: 6.2156 - val_mse: 6.2156 - 28ms/epoch - 9ms/step\n",
      "Epoch 97/200\n",
      "3/3 - 0s - loss: 2.3639 - mse: 2.3639 - val_loss: 6.2644 - val_mse: 6.2644 - 28ms/epoch - 9ms/step\n",
      "Epoch 98/200\n",
      "3/3 - 0s - loss: 2.1798 - mse: 2.1798 - val_loss: 6.2861 - val_mse: 6.2861 - 28ms/epoch - 9ms/step\n",
      "Epoch 99/200\n",
      "3/3 - 0s - loss: 2.3098 - mse: 2.3098 - val_loss: 6.2751 - val_mse: 6.2751 - 28ms/epoch - 9ms/step\n",
      "Epoch 100/200\n",
      "3/3 - 0s - loss: 2.2424 - mse: 2.2424 - val_loss: 6.2363 - val_mse: 6.2363 - 28ms/epoch - 9ms/step\n",
      "Epoch 101/200\n",
      "3/3 - 0s - loss: 2.2218 - mse: 2.2218 - val_loss: 6.1926 - val_mse: 6.1926 - 28ms/epoch - 9ms/step\n",
      "Epoch 102/200\n",
      "3/3 - 0s - loss: 2.3998 - mse: 2.3998 - val_loss: 6.1634 - val_mse: 6.1634 - 28ms/epoch - 9ms/step\n",
      "Epoch 103/200\n",
      "3/3 - 0s - loss: 2.1346 - mse: 2.1346 - val_loss: 6.1214 - val_mse: 6.1214 - 31ms/epoch - 10ms/step\n",
      "Epoch 104/200\n",
      "3/3 - 0s - loss: 2.7222 - mse: 2.7222 - val_loss: 6.1290 - val_mse: 6.1290 - 27ms/epoch - 9ms/step\n",
      "Epoch 105/200\n",
      "3/3 - 0s - loss: 2.0418 - mse: 2.0418 - val_loss: 6.1551 - val_mse: 6.1551 - 28ms/epoch - 9ms/step\n",
      "Epoch 106/200\n",
      "3/3 - 0s - loss: 2.1638 - mse: 2.1638 - val_loss: 6.1972 - val_mse: 6.1972 - 29ms/epoch - 10ms/step\n",
      "Epoch 107/200\n",
      "3/3 - 0s - loss: 2.3917 - mse: 2.3917 - val_loss: 6.2495 - val_mse: 6.2495 - 28ms/epoch - 9ms/step\n",
      "Epoch 108/200\n",
      "3/3 - 0s - loss: 2.6023 - mse: 2.6023 - val_loss: 6.2742 - val_mse: 6.2742 - 28ms/epoch - 9ms/step\n",
      "Epoch 109/200\n",
      "3/3 - 0s - loss: 2.3460 - mse: 2.3460 - val_loss: 6.3081 - val_mse: 6.3081 - 28ms/epoch - 9ms/step\n",
      "Epoch 110/200\n",
      "3/3 - 0s - loss: 1.9833 - mse: 1.9833 - val_loss: 6.3801 - val_mse: 6.3801 - 28ms/epoch - 9ms/step\n",
      "Epoch 111/200\n",
      "3/3 - 0s - loss: 2.1754 - mse: 2.1754 - val_loss: 6.3656 - val_mse: 6.3656 - 28ms/epoch - 9ms/step\n",
      "Epoch 112/200\n",
      "3/3 - 0s - loss: 2.2873 - mse: 2.2873 - val_loss: 6.3479 - val_mse: 6.3479 - 28ms/epoch - 9ms/step\n",
      "Epoch 113/200\n",
      "3/3 - 0s - loss: 2.3582 - mse: 2.3582 - val_loss: 6.3378 - val_mse: 6.3378 - 28ms/epoch - 9ms/step\n",
      "Epoch 114/200\n",
      "3/3 - 0s - loss: 2.0673 - mse: 2.0673 - val_loss: 6.3355 - val_mse: 6.3355 - 27ms/epoch - 9ms/step\n",
      "Epoch 115/200\n",
      "3/3 - 0s - loss: 2.1008 - mse: 2.1008 - val_loss: 6.3535 - val_mse: 6.3535 - 28ms/epoch - 9ms/step\n",
      "Epoch 116/200\n",
      "3/3 - 0s - loss: 1.9807 - mse: 1.9807 - val_loss: 6.4069 - val_mse: 6.4069 - 28ms/epoch - 9ms/step\n",
      "Epoch 117/200\n",
      "3/3 - 0s - loss: 2.1603 - mse: 2.1603 - val_loss: 6.4301 - val_mse: 6.4301 - 28ms/epoch - 9ms/step\n",
      "Epoch 118/200\n",
      "3/3 - 0s - loss: 2.1350 - mse: 2.1350 - val_loss: 6.4163 - val_mse: 6.4163 - 28ms/epoch - 9ms/step\n",
      "Epoch 119/200\n",
      "3/3 - 0s - loss: 2.3586 - mse: 2.3586 - val_loss: 6.3714 - val_mse: 6.3714 - 28ms/epoch - 9ms/step\n",
      "Epoch 120/200\n",
      "3/3 - 0s - loss: 2.0780 - mse: 2.0780 - val_loss: 6.3237 - val_mse: 6.3237 - 28ms/epoch - 9ms/step\n",
      "Epoch 121/200\n",
      "3/3 - 0s - loss: 2.0844 - mse: 2.0844 - val_loss: 6.2896 - val_mse: 6.2896 - 29ms/epoch - 10ms/step\n",
      "Epoch 122/200\n",
      "3/3 - 0s - loss: 2.2220 - mse: 2.2220 - val_loss: 6.2668 - val_mse: 6.2668 - 28ms/epoch - 9ms/step\n",
      "Epoch 123/200\n",
      "3/3 - 0s - loss: 2.0243 - mse: 2.0243 - val_loss: 6.2317 - val_mse: 6.2317 - 28ms/epoch - 9ms/step\n",
      "Epoch 124/200\n",
      "3/3 - 0s - loss: 2.1483 - mse: 2.1483 - val_loss: 6.1554 - val_mse: 6.1554 - 28ms/epoch - 9ms/step\n",
      "Epoch 125/200\n",
      "3/3 - 0s - loss: 2.7560 - mse: 2.7560 - val_loss: 6.1133 - val_mse: 6.1133 - 31ms/epoch - 10ms/step\n",
      "Epoch 126/200\n",
      "3/3 - 0s - loss: 2.0065 - mse: 2.0065 - val_loss: 6.0961 - val_mse: 6.0961 - 31ms/epoch - 10ms/step\n",
      "Epoch 127/200\n",
      "3/3 - 0s - loss: 2.1358 - mse: 2.1358 - val_loss: 6.1027 - val_mse: 6.1027 - 28ms/epoch - 9ms/step\n",
      "Epoch 128/200\n",
      "3/3 - 0s - loss: 2.0651 - mse: 2.0651 - val_loss: 6.1231 - val_mse: 6.1231 - 28ms/epoch - 9ms/step\n",
      "Epoch 129/200\n",
      "3/3 - 0s - loss: 2.0621 - mse: 2.0621 - val_loss: 6.1614 - val_mse: 6.1614 - 28ms/epoch - 9ms/step\n",
      "Epoch 130/200\n",
      "3/3 - 0s - loss: 2.0912 - mse: 2.0912 - val_loss: 6.1965 - val_mse: 6.1965 - 28ms/epoch - 9ms/step\n",
      "Epoch 131/200\n",
      "3/3 - 0s - loss: 2.2427 - mse: 2.2427 - val_loss: 6.2266 - val_mse: 6.2266 - 28ms/epoch - 9ms/step\n",
      "Epoch 132/200\n",
      "3/3 - 0s - loss: 2.0692 - mse: 2.0692 - val_loss: 6.2574 - val_mse: 6.2574 - 28ms/epoch - 9ms/step\n",
      "Epoch 133/200\n",
      "3/3 - 0s - loss: 2.0990 - mse: 2.0990 - val_loss: 6.3027 - val_mse: 6.3027 - 28ms/epoch - 9ms/step\n",
      "Epoch 134/200\n",
      "3/3 - 0s - loss: 2.0843 - mse: 2.0843 - val_loss: 6.3679 - val_mse: 6.3679 - 28ms/epoch - 9ms/step\n",
      "Epoch 135/200\n",
      "3/3 - 0s - loss: 1.9867 - mse: 1.9867 - val_loss: 6.3929 - val_mse: 6.3929 - 28ms/epoch - 9ms/step\n",
      "Epoch 136/200\n",
      "3/3 - 0s - loss: 1.9348 - mse: 1.9348 - val_loss: 6.3848 - val_mse: 6.3848 - 28ms/epoch - 9ms/step\n",
      "Epoch 137/200\n",
      "3/3 - 0s - loss: 2.2558 - mse: 2.2558 - val_loss: 6.3826 - val_mse: 6.3826 - 28ms/epoch - 9ms/step\n",
      "Epoch 138/200\n",
      "3/3 - 0s - loss: 2.1109 - mse: 2.1109 - val_loss: 6.3745 - val_mse: 6.3745 - 28ms/epoch - 9ms/step\n",
      "Epoch 139/200\n",
      "3/3 - 0s - loss: 2.1072 - mse: 2.1072 - val_loss: 6.3522 - val_mse: 6.3522 - 28ms/epoch - 9ms/step\n",
      "Epoch 140/200\n",
      "3/3 - 0s - loss: 2.0578 - mse: 2.0578 - val_loss: 6.3197 - val_mse: 6.3197 - 28ms/epoch - 9ms/step\n",
      "Epoch 141/200\n",
      "3/3 - 0s - loss: 1.9508 - mse: 1.9508 - val_loss: 6.3031 - val_mse: 6.3031 - 28ms/epoch - 9ms/step\n",
      "Epoch 142/200\n",
      "3/3 - 0s - loss: 1.9934 - mse: 1.9934 - val_loss: 6.3436 - val_mse: 6.3436 - 28ms/epoch - 9ms/step\n",
      "Epoch 143/200\n",
      "3/3 - 0s - loss: 2.3113 - mse: 2.3113 - val_loss: 6.3643 - val_mse: 6.3643 - 28ms/epoch - 9ms/step\n",
      "Epoch 144/200\n",
      "3/3 - 0s - loss: 2.3209 - mse: 2.3209 - val_loss: 6.3922 - val_mse: 6.3922 - 28ms/epoch - 9ms/step\n",
      "Epoch 145/200\n",
      "3/3 - 0s - loss: 1.9942 - mse: 1.9942 - val_loss: 6.4482 - val_mse: 6.4482 - 29ms/epoch - 10ms/step\n",
      "Epoch 146/200\n",
      "3/3 - 0s - loss: 1.9063 - mse: 1.9063 - val_loss: 6.4543 - val_mse: 6.4543 - 28ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      "3/3 - 0s - loss: 2.0627 - mse: 2.0627 - val_loss: 6.4408 - val_mse: 6.4408 - 28ms/epoch - 9ms/step\n",
      "Epoch 148/200\n",
      "3/3 - 0s - loss: 1.8104 - mse: 1.8104 - val_loss: 6.3905 - val_mse: 6.3905 - 28ms/epoch - 9ms/step\n",
      "Epoch 149/200\n",
      "3/3 - 0s - loss: 1.9432 - mse: 1.9432 - val_loss: 6.3619 - val_mse: 6.3619 - 28ms/epoch - 9ms/step\n",
      "Epoch 150/200\n",
      "3/3 - 0s - loss: 2.1959 - mse: 2.1959 - val_loss: 6.4055 - val_mse: 6.4055 - 28ms/epoch - 9ms/step\n",
      "Epoch 151/200\n",
      "3/3 - 0s - loss: 2.0215 - mse: 2.0215 - val_loss: 6.4596 - val_mse: 6.4596 - 31ms/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 17:20:06.312688: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Select number of hidden units\n",
    "layer_1_units = 32\n",
    "layer_2_units = 32\n",
    "# Select whether to batch normalize\n",
    "batch_normalization = False,\n",
    "\n",
    "# Build and compile model\n",
    "model = build_mlp(X_train,\n",
    "                  layer_1_units = layer_1_units,\n",
    "                  layer_2_units = layer_2_units,\n",
    "                  batch_normalization = batch_normalization,\n",
    "                  **compile_hp)\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, **fit_hp)\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"neural_network-32_32\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4577144",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.969422</td>\n",
       "      <td>1.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-32_32</td>\n",
       "      <td>1.690016</td>\n",
       "      <td>2.073730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_128</td>\n",
       "      <td>2.119378</td>\n",
       "      <td>2.127424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-128_128</td>\n",
       "      <td>2.424878</td>\n",
       "      <td>2.326648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64_init_bn</td>\n",
       "      <td>1.849187</td>\n",
       "      <td>2.391446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  train_rmse  test_rmse\n",
       "0                        linear    1.969422   1.888512\n",
       "0          neural_network-32_32    1.690016   2.073730\n",
       "0         neural_network-64_128    2.119378   2.127424\n",
       "0        neural_network-128_128    2.424878   2.326648\n",
       "0  neural_network-64_64_init_bn    1.849187   2.391446"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.sort_values(\"test_rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee964fa5",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19b05d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params to compile model with\n",
    "fixed_params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': \"rmse\",  \n",
    "        'verbosity': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d0fff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    \"\"\"\n",
    "    Wrapper function to work with Optuna trial objects, \n",
    "    enabling Hyperband hyperparameter search.\n",
    "    \"\"\"   \n",
    "    # Suggest hyperparams to test using Optuna trial object.\n",
    "    param = {**fixed_params,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 3000, step = 20),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.2, 0.99, step = 0.05),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.2, 0.99, step = 0.05),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 5000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 2000, step=5),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 10),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "    }\n",
    "    \n",
    "    # Create cv object\n",
    "    cv = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "    # Make empty array to store cv RMSE scores in\n",
    "    cv_scores = np.empty(5)\n",
    "    \n",
    "    # Split into K train and validation sets and iterate through them\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        # Split into training and validation CV sets\n",
    "        X_train_cv, X_test_cv = X[train_idx], X[test_idx]\n",
    "        y_train_cv, y_test_cv = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Convert data to proper LGBM format\n",
    "        train_data = lgb.Dataset(X_train_cv, label = y_train_cv,\n",
    "                                 categorical_feature = [0,1,2,3,4,6,7,8])\n",
    "        val_data = lgb.Dataset(X_test_cv, label = y_test_cv, \n",
    "                               categorical_feature = [0,1,2,3,4,6,7,8],\n",
    "                              reference = train_data)\n",
    "        \n",
    "        # Make callbacks to prevent trialling hyperparams that are obviously bad\n",
    "        callbacks = [\n",
    "            LightGBMPruningCallback(trial, metric = \"rmse\"),\n",
    "                     # Callback to reduce model validation performance messages\n",
    "                    lgb.log_evaluation(period = 100),\n",
    "                     # Early stoppping to prevent overfitting training data\n",
    "                    lgb.early_stopping(100)]\n",
    "\n",
    "        # Training the model\n",
    "        model = lgb.train(params = param,  train_set = train_data,\n",
    "                          valid_sets = val_data,   \n",
    "                          callbacks = callbacks,\n",
    "                         )\n",
    "    \n",
    "        # Get predictions\n",
    "        preds = model.predict(X_test_cv)\n",
    "        # Calculate RMSE\n",
    "        cv_scores[idx] = mean_squared_error(y_test_cv, preds, squared = False)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ab4bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture my_study\n",
    "# Above line magic hides lengthy output, but stores into first_round if you want to look\n",
    "\n",
    "# Create Optuna study to do CV hyperparameter search\n",
    "study = optuna.create_study(direction = \"minimize\", # minimizing RMSE\n",
    "                            study_name = \"LGBM Classifier\",\n",
    "                           pruner = optuna.pruners.HyperbandPruner())\n",
    "func = lambda trial: objective(trial, X = X_train, y = y_train)\n",
    "study.optimize(func, n_trials = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ae504ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=69 will be ignored. Current value: min_data_in_leaf=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/miniforge3/envs/skywalker/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "# Run best model and evaluate\n",
    "# Convert data to proper LGBM format\n",
    "train_data = lgb.Dataset(X_train, label = y_train,\n",
    "                         categorical_feature = [0,1,2,3,4,6,7,8])\n",
    "\n",
    "# Callback to reduce model messages\n",
    "callbacks = [lgb.log_evaluation(period = 100)]\n",
    "\n",
    "# Training the model using the best params identified in study\n",
    "model = lgb.train(params = {**fixed_params, **study.best_params},\n",
    "                  train_set = train_data, \n",
    "                  callbacks = callbacks,\n",
    "                 )\n",
    "\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         model, \"lgbm\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5be8cf",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd2127a",
   "metadata": {},
   "source": [
    "### RBF SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ee6f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "svr = SVR()\n",
    "# Fit\n",
    "svr.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         svr, \"svm_rbf\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528c498",
   "metadata": {},
   "source": [
    "### LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8657683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/miniforge3/envs/skywalker/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>2.044915</td>\n",
       "      <td>1.732313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>1.915254</td>\n",
       "      <td>1.803835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.969422</td>\n",
       "      <td>1.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-32_32</td>\n",
       "      <td>1.690016</td>\n",
       "      <td>2.073730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear-0.499</td>\n",
       "      <td>2.054832</td>\n",
       "      <td>2.118775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_128</td>\n",
       "      <td>2.119378</td>\n",
       "      <td>2.127424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-128_128</td>\n",
       "      <td>2.424878</td>\n",
       "      <td>2.326648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network-64_64_init_bn</td>\n",
       "      <td>1.849187</td>\n",
       "      <td>2.391446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  train_rmse  test_rmse\n",
       "0                       svm_rbf    2.044915   1.732313\n",
       "0                          lgbm    1.915254   1.803835\n",
       "0                        linear    1.969422   1.888512\n",
       "0          neural_network-32_32    1.690016   2.073730\n",
       "0              svm_linear-0.499    2.054832   2.118775\n",
       "0         neural_network-64_128    2.119378   2.127424\n",
       "0        neural_network-128_128    2.424878   2.326648\n",
       "0  neural_network-64_64_init_bn    1.849187   2.391446"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "epsilon = 0.499\n",
    "svr = LinearSVR(epsilon = epsilon)\n",
    "# Fit\n",
    "svr.fit(X_train, y_train)\n",
    "# Evaluate model, getting test and train RMSE\n",
    "results = evaluate_model(X_train, X_test,\n",
    "                         y_train, y_test,\n",
    "                         svr, f\"svm_linear-{epsilon}\")\n",
    "# Store results\n",
    "all_results = pd.concat([all_results, results])\n",
    "all_results.sort_values(\"test_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5572e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
